{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# General imports\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import norm\n",
    "import time\n",
    "import sys\n",
    "from PIL import Image\n",
    "from mpl_toolkits.mplot3d import axes3d, Axes3D\n",
    "\n",
    "# Tensorflow\n",
    "import tensorflow as tf\n",
    "\n",
    "# Keras imports\n",
    "from keras.layers import Input, Dense, Lambda, Conv1D, Flatten, Reshape, BatchNormalization, Conv2DTranspose\n",
    "from keras.models import Model, load_model\n",
    "from keras import backend as K\n",
    "from keras import metrics\n",
    "from keras import losses\n",
    "from keras import initializers\n",
    "from keras.datasets import mnist\n",
    "from keras.callbacks import TensorBoard,ReduceLROnPlateau,ModelCheckpoint\n",
    "from keras import optimizers\n",
    "\n",
    "# Os.path\n",
    "from os.path import exists, join, abspath\n",
    "from os import makedirs, getcwd\n",
    "\n",
    "\n",
    "# Windows short path\n",
    "import win32api\n",
    "\n",
    "# Interactive plotting\n",
    "import PyQt5\n",
    "%matplotlib qt5\n",
    "# # Plot inline\n",
    "# %matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Generation\n",
    "We will be using the same sinusoid data from previous experiments. We generate the data and save it in memory due to its simplicity.-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_phases = 100\n",
    "time_samples = 50\n",
    "omega_value = 2*np.pi\n",
    "# Phases used\n",
    "phase_range = 2*np.pi*np.linspace(0,1,num_phases)\n",
    "time_range = np.linspace(0,1,time_samples)\n",
    "# Signals\n",
    "signals = np.sin(np.subtract.outer(phase_range,-(omega_value * time_range)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VAE characteristics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "latent_dim = 1\n",
    "intermediate_dim = int(time_samples/3)\n",
    "epsilon_std = 1.0\n",
    "L = 1.0\n",
    "N = 1000\n",
    "filters = 64\n",
    "kernel_size = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VAE Encoder\n",
    "log_t = -10.0\n",
    "input_signal = Input(shape=(time_samples,), name='input_signal')\n",
    "reshape_input = Reshape(target_shape=(time_samples,1))(input_signal)\n",
    "c1 = Conv1D(filters, kernel_size, strides=1,activation='relu', name='c1')(reshape_input)\n",
    "c2 = Conv1D(filters, kernel_size, strides=1,activation='relu', name='c2')(c1)\n",
    "c3 = Conv1D(filters, kernel_size, strides=1,activation='linear', name='c3')(c2)\n",
    "flatten = Flatten()(c3)\n",
    "z_mean = Dense(latent_dim, name='z_mean', activation='linear')(flatten)\n",
    "encoder = Model(input_signal, z_mean)\n",
    "# encoder_sigma = Model(input_signal, log_t)\n",
    "\n",
    "def sampling(args):\n",
    "    z_mean = args \n",
    "    epsilon = K.random_normal(shape=(batch_size, latent_dim),\n",
    "                              mean=0.0, stddev=epsilon_std)\n",
    "    g_epsilon = tf.mod(z_mean+L+tf.scalar_mul(np.exp(log_t),epsilon),2*L)-L\n",
    "    return g_epsilon\n",
    "\n",
    "z = Lambda(sampling, output_shape=(latent_dim,), name='sampling')(z_mean)\n",
    "\n",
    "# VAE Decoding\n",
    "hd1_layer = Dense(intermediate_dim, activation = 'relu', name = 'hd1')\n",
    "hd2_layer = Dense(time_samples, activation = 'relu', name = 'hd2')\n",
    "reconstruct_layer = Dense(time_samples, activation = 'linear', name = 'reconstructed')\n",
    "\n",
    "hd1 = hd1_layer(z)\n",
    "hd2 = hd2_layer(hd1)\n",
    "reconstructed = reconstruct_layer(hd2)\n",
    "\n",
    "vae = Model(input_signal,reconstructed)\n",
    "\n",
    "# Decoder\n",
    "_z = Input(shape=(latent_dim,), name='decoder_input')\n",
    "_hd1 = hd1_layer(_z)\n",
    "_hd2 = hd2_layer(_hd1)\n",
    "_reconstructed = reconstruct_layer(_hd2)\n",
    "decoder = Model(_z,_reconstructed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_signal (InputLayer)    (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "reshape_2 (Reshape)          (None, 50, 1)             0         \n",
      "_________________________________________________________________\n",
      "c1 (Conv1D)                  (None, 48, 64)            256       \n",
      "_________________________________________________________________\n",
      "c2 (Conv1D)                  (None, 46, 64)            12352     \n",
      "_________________________________________________________________\n",
      "c3 (Conv1D)                  (None, 44, 64)            12352     \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 2816)              0         \n",
      "_________________________________________________________________\n",
      "z_mean (Dense)               (None, 1)                 2817      \n",
      "_________________________________________________________________\n",
      "sampling (Lambda)            (None, 1)                 0         \n",
      "_________________________________________________________________\n",
      "hd1 (Dense)                  (None, 16)                32        \n",
      "_________________________________________________________________\n",
      "hd2 (Dense)                  (None, 50)                850       \n",
      "_________________________________________________________________\n",
      "reconstructed (Dense)        (None, 50)                2550      \n",
      "=================================================================\n",
      "Total params: 31,209\n",
      "Trainable params: 31,209\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vae.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xent_loss(x, xr):\n",
    "    xent_loss = K.mean(losses.mean_squared_error(x, xr))\n",
    "    return xent_loss\n",
    "\n",
    "def heat_loss(x, xr):\n",
    "    # Range for the sum of the Fourier expansion\n",
    "    sum_range = tf.range(1,N+1,dtype = np.float32)\n",
    "    sum_range_t = tf.reshape(sum_range,[latent_dim,N])\n",
    "    # Fourier sum terms\n",
    "    position = tf.scalar_mul(np.pi/L,z_mean-z) #Position \n",
    "    cosine = tf.cos(tf.matmul(position, sum_range_t))\n",
    "    # Temporal term\n",
    "    quadratic_term = tf.pow(tf.scalar_mul(np.pi/L,sum_range),2)\n",
    "    exponent = tf.scalar_mul(-tf.exp(log_t),quadratic_term)\n",
    "    exponential = tf.exp(exponent)\n",
    "    # Series sum from n = 1 to N\n",
    "    summand = tf.multiply(cosine,exponential)\n",
    "    return tf.log(tf.abs((1/(2*L))+(1/L)*tf.reduce_sum(summand,axis=-1)))\n",
    "\n",
    "def vae_loss(x, x_decoded_mean):\n",
    "    return xent_loss(x, x_decoded_mean)+heat_loss(x, x_decoded_mean)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_vae = {\"optimizer\":optimizers.RMSprop(lr=0.000001,\n",
    "                                                 rho=0.9,\n",
    "                                                 epsilon=None,\n",
    "                                                 decay=0.0),\n",
    "                 \"loss\":vae_loss, \n",
    "                 \"metrics\":[xent_loss, heat_loss]}\n",
    "vae.compile(**parameters_vae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving experiment files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LUISPR~1\\DOCUME~1\\Master\\TUE\\FINALP~1\\Python\\models\\HE242F~1\\TENSOR~1\n"
     ]
    }
   ],
   "source": [
    "# File naming variables\n",
    "experiment_name = 'HeatKernelTFix' # Code for the experiment\n",
    "timestr = time.strftime(\"%Y-%m-%d-%H-%M_\") # Timestamp\n",
    "extra_comments ='_LinearOutput' # Extra comments of the experiment\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Folder for saving the different models\n",
    "folder_models = join(getcwd(),'models', experiment_name)\n",
    "if not exists(folder_models):\n",
    "    makedirs(folder_models)\n",
    "    \n",
    "# Folder for the generator, the encoder and the vae models. Also tensorboard\n",
    "folder_dictionary = {'generator':join(folder_models,'generator'),\n",
    "                    'encoder':join(folder_models,'encoder'),\n",
    "                    'encoder_sigma':join(folder_models,'encoder_sigma'),\n",
    "                    'vae':join(folder_models,'vae'),\n",
    "                    'tensorboard':join(folder_models,'tensorboard'),\n",
    "                    'images':join(folder_models,'images')}\n",
    "for folder in folder_dictionary:\n",
    "    if not exists(folder_dictionary[folder]):\n",
    "        makedirs(folder_dictionary[folder])\n",
    "        \n",
    "log_dir_tensorboard =join(win32api.GetShortPathName(folder_dictionary['tensorboard']),timestr, extra_comments)\n",
    "print(win32api.GetShortPathName(folder_dictionary['tensorboard']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10000\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 4.2343 - xent_loss: 0.4998 - heat_loss: 3.7345\n",
      "Epoch 2/10000\n",
      "100/100 [==============================] - 0s 318us/step - loss: 4.2343 - xent_loss: 0.4998 - heat_loss: 3.7345\n",
      "Epoch 3/10000\n",
      "100/100 [==============================] - 0s 325us/step - loss: 4.2343 - xent_loss: 0.4998 - heat_loss: 3.7345\n",
      "Epoch 4/10000\n",
      "100/100 [==============================] - 0s 356us/step - loss: 4.2342 - xent_loss: 0.4998 - heat_loss: 3.7345\n",
      "Epoch 5/10000\n",
      "100/100 [==============================] - 0s 415us/step - loss: 4.2342 - xent_loss: 0.4998 - heat_loss: 3.7345\n",
      "Epoch 6/10000\n",
      "100/100 [==============================] - 0s 401us/step - loss: 4.2342 - xent_loss: 0.4998 - heat_loss: 3.7345\n",
      "Epoch 7/10000\n",
      "100/100 [==============================] - 0s 943us/step - loss: 4.2342 - xent_loss: 0.4997 - heat_loss: 3.7345\n",
      "Epoch 8/10000\n",
      "100/100 [==============================] - 0s 412us/step - loss: 4.2342 - xent_loss: 0.4997 - heat_loss: 3.7345\n",
      "Epoch 9/10000\n",
      "100/100 [==============================] - 0s 341us/step - loss: 4.2342 - xent_loss: 0.4997 - heat_loss: 3.7345\n",
      "Epoch 10/10000\n",
      "100/100 [==============================] - 0s 402us/step - loss: 4.2342 - xent_loss: 0.4997 - heat_loss: 3.7345\n",
      "Epoch 11/10000\n",
      "100/100 [==============================] - 0s 392us/step - loss: 4.2342 - xent_loss: 0.4997 - heat_loss: 3.7345\n",
      "Epoch 12/10000\n",
      "100/100 [==============================] - 0s 346us/step - loss: 4.2342 - xent_loss: 0.4997 - heat_loss: 3.7345\n",
      "Epoch 13/10000\n",
      "100/100 [==============================] - 0s 292us/step - loss: 4.2342 - xent_loss: 0.4997 - heat_loss: 3.7345\n",
      "Epoch 14/10000\n",
      "100/100 [==============================] - 0s 613us/step - loss: 4.2342 - xent_loss: 0.4997 - heat_loss: 3.7345\n",
      "Epoch 15/10000\n",
      "100/100 [==============================] - 0s 381us/step - loss: 4.2342 - xent_loss: 0.4997 - heat_loss: 3.7345\n",
      "Epoch 16/10000\n",
      "100/100 [==============================] - 0s 366us/step - loss: 4.2342 - xent_loss: 0.4997 - heat_loss: 3.7345\n",
      "Epoch 17/10000\n",
      "100/100 [==============================] - 0s 411us/step - loss: 4.2342 - xent_loss: 0.4997 - heat_loss: 3.7345\n",
      "Epoch 18/10000\n",
      "100/100 [==============================] - 0s 358us/step - loss: 4.2342 - xent_loss: 0.4997 - heat_loss: 3.7345\n",
      "Epoch 19/10000\n",
      "100/100 [==============================] - 0s 421us/step - loss: 4.2342 - xent_loss: 0.4997 - heat_loss: 3.7345\n",
      "Epoch 20/10000\n",
      "100/100 [==============================] - 0s 922us/step - loss: 4.2342 - xent_loss: 0.4997 - heat_loss: 3.7345\n",
      "Epoch 21/10000\n",
      "100/100 [==============================] - 0s 411us/step - loss: 4.2341 - xent_loss: 0.4997 - heat_loss: 3.7345\n",
      "Epoch 22/10000\n",
      "100/100 [==============================] - 0s 531us/step - loss: 4.2341 - xent_loss: 0.4997 - heat_loss: 3.7345\n",
      "Epoch 23/10000\n",
      "100/100 [==============================] - 0s 441us/step - loss: 4.2341 - xent_loss: 0.4997 - heat_loss: 3.7345\n",
      "Epoch 24/10000\n",
      "100/100 [==============================] - 0s 461us/step - loss: 4.2341 - xent_loss: 0.4997 - heat_loss: 3.7345\n",
      "Epoch 25/10000\n",
      "100/100 [==============================] - 0s 722us/step - loss: 4.2341 - xent_loss: 0.4997 - heat_loss: 3.7345\n",
      "Epoch 26/10000\n",
      "100/100 [==============================] - 0s 421us/step - loss: 4.2341 - xent_loss: 0.4997 - heat_loss: 3.7345\n",
      "Epoch 27/10000\n",
      "100/100 [==============================] - 0s 501us/step - loss: 4.2341 - xent_loss: 0.4996 - heat_loss: 3.7345\n",
      "Epoch 28/10000\n",
      "100/100 [==============================] - 0s 501us/step - loss: 4.2341 - xent_loss: 0.4996 - heat_loss: 3.7345\n",
      "Epoch 29/10000\n",
      "100/100 [==============================] - 0s 531us/step - loss: 4.2341 - xent_loss: 0.4996 - heat_loss: 3.7345\n",
      "Epoch 30/10000\n",
      "100/100 [==============================] - 0s 411us/step - loss: 4.2341 - xent_loss: 0.4996 - heat_loss: 3.7345\n",
      "Epoch 31/10000\n",
      "100/100 [==============================] - 0s 541us/step - loss: 4.2341 - xent_loss: 0.4996 - heat_loss: 3.7345\n",
      "Epoch 32/10000\n",
      "100/100 [==============================] - 0s 471us/step - loss: 4.2341 - xent_loss: 0.4996 - heat_loss: 3.7345\n",
      "Epoch 33/10000\n",
      "100/100 [==============================] - 0s 501us/step - loss: 4.2341 - xent_loss: 0.4996 - heat_loss: 3.7345\n",
      "Epoch 34/10000\n",
      "100/100 [==============================] - 0s 532us/step - loss: 4.2341 - xent_loss: 0.4996 - heat_loss: 3.7345\n",
      "Epoch 35/10000\n",
      "100/100 [==============================] - 0s 381us/step - loss: 4.2341 - xent_loss: 0.4996 - heat_loss: 3.7345\n",
      "Epoch 36/10000\n",
      "100/100 [==============================] - 0s 411us/step - loss: 4.2341 - xent_loss: 0.4996 - heat_loss: 3.7345\n",
      "Epoch 37/10000\n",
      "100/100 [==============================] - 0s 361us/step - loss: 4.2341 - xent_loss: 0.4996 - heat_loss: 3.7345\n",
      "Epoch 38/10000\n",
      "100/100 [==============================] - 0s 461us/step - loss: 4.2341 - xent_loss: 0.4996 - heat_loss: 3.7345\n",
      "Epoch 39/10000\n",
      "100/100 [==============================] - 0s 391us/step - loss: 4.2341 - xent_loss: 0.4996 - heat_loss: 3.7345\n",
      "Epoch 40/10000\n",
      "100/100 [==============================] - 0s 361us/step - loss: 4.2341 - xent_loss: 0.4996 - heat_loss: 3.7345\n",
      "Epoch 41/10000\n",
      "100/100 [==============================] - 0s 391us/step - loss: 4.2341 - xent_loss: 0.4996 - heat_loss: 3.7345\n",
      "Epoch 42/10000\n",
      "100/100 [==============================] - 0s 381us/step - loss: 4.2341 - xent_loss: 0.4996 - heat_loss: 3.7345\n",
      "Epoch 43/10000\n",
      "100/100 [==============================] - 0s 421us/step - loss: 4.2341 - xent_loss: 0.4996 - heat_loss: 3.7345\n",
      "Epoch 44/10000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.2341 - xent_loss: 0.4996 - heat_loss: 3.7345\n",
      "Epoch 45/10000\n",
      "100/100 [==============================] - 0s 441us/step - loss: 4.2340 - xent_loss: 0.4996 - heat_loss: 3.7345\n",
      "Epoch 46/10000\n",
      "100/100 [==============================] - 0s 652us/step - loss: 4.2340 - xent_loss: 0.4996 - heat_loss: 3.7345\n",
      "Epoch 47/10000\n",
      "100/100 [==============================] - 0s 371us/step - loss: 4.2340 - xent_loss: 0.4996 - heat_loss: 3.7345\n",
      "Epoch 48/10000\n",
      "100/100 [==============================] - 0s 832us/step - loss: 4.2340 - xent_loss: 0.4996 - heat_loss: 3.7345\n",
      "Epoch 49/10000\n",
      "100/100 [==============================] - 0s 772us/step - loss: 4.2340 - xent_loss: 0.4996 - heat_loss: 3.7345\n",
      "Epoch 50/10000\n",
      "100/100 [==============================] - 0s 361us/step - loss: 4.2340 - xent_loss: 0.4996 - heat_loss: 3.7345\n",
      "Epoch 51/10000\n",
      "100/100 [==============================] - 0s 461us/step - loss: 4.2340 - xent_loss: 0.4995 - heat_loss: 3.7345\n",
      "Epoch 52/10000\n",
      "100/100 [==============================] - 0s 431us/step - loss: 4.2340 - xent_loss: 0.4995 - heat_loss: 3.7345\n",
      "Epoch 53/10000\n",
      "100/100 [==============================] - 0s 652us/step - loss: 4.2340 - xent_loss: 0.4995 - heat_loss: 3.7345\n",
      "Epoch 54/10000\n",
      "100/100 [==============================] - 0s 391us/step - loss: 4.2340 - xent_loss: 0.4995 - heat_loss: 3.7345\n",
      "Epoch 55/10000\n",
      "100/100 [==============================] - 0s 973us/step - loss: 4.2340 - xent_loss: 0.4995 - heat_loss: 3.7345\n",
      "Epoch 56/10000\n",
      "100/100 [==============================] - 0s 351us/step - loss: 4.2340 - xent_loss: 0.4995 - heat_loss: 3.7345\n",
      "Epoch 57/10000\n",
      "100/100 [==============================] - 0s 361us/step - loss: 4.2340 - xent_loss: 0.4995 - heat_loss: 3.7345\n",
      "Epoch 58/10000\n",
      "100/100 [==============================] - 0s 942us/step - loss: 4.2340 - xent_loss: 0.4995 - heat_loss: 3.7345\n",
      "Epoch 59/10000\n",
      "100/100 [==============================] - 0s 351us/step - loss: 4.2340 - xent_loss: 0.4995 - heat_loss: 3.7345\n",
      "Epoch 60/10000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.2340 - xent_loss: 0.4995 - heat_loss: 3.7345\n",
      "Epoch 61/10000\n",
      "100/100 [==============================] - 0s 411us/step - loss: 4.2340 - xent_loss: 0.4995 - heat_loss: 3.7345\n",
      "Epoch 62/10000\n",
      "100/100 [==============================] - 0s 912us/step - loss: 4.2340 - xent_loss: 0.4995 - heat_loss: 3.7345\n",
      "Epoch 63/10000\n",
      "100/100 [==============================] - 0s 882us/step - loss: 4.2340 - xent_loss: 0.4995 - heat_loss: 3.7345\n",
      "Epoch 64/10000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.2340 - xent_loss: 0.4995 - heat_loss: 3.7345\n",
      "Epoch 65/10000\n",
      "100/100 [==============================] - 0s 832us/step - loss: 4.2340 - xent_loss: 0.4995 - heat_loss: 3.7345\n",
      "Epoch 66/10000\n",
      "100/100 [==============================] - 0s 872us/step - loss: 4.2340 - xent_loss: 0.4995 - heat_loss: 3.7345\n",
      "Epoch 67/10000\n",
      "100/100 [==============================] - 0s 391us/step - loss: 4.2340 - xent_loss: 0.4995 - heat_loss: 3.7345\n",
      "Epoch 68/10000\n",
      "100/100 [==============================] - 0s 973us/step - loss: 4.2340 - xent_loss: 0.4995 - heat_loss: 3.7345\n",
      "Epoch 69/10000\n",
      "100/100 [==============================] - 0s 401us/step - loss: 4.2339 - xent_loss: 0.4995 - heat_loss: 3.7345\n",
      "Epoch 70/10000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.2339 - xent_loss: 0.4995 - heat_loss: 3.7345\n",
      "Epoch 71/10000\n",
      "100/100 [==============================] - 0s 862us/step - loss: 4.2339 - xent_loss: 0.4995 - heat_loss: 3.7345\n",
      "Epoch 72/10000\n",
      "100/100 [==============================] - 0s 933us/step - loss: 4.2339 - xent_loss: 0.4995 - heat_loss: 3.7345\n",
      "Epoch 73/10000\n",
      "100/100 [==============================] - 0s 812us/step - loss: 4.2339 - xent_loss: 0.4995 - heat_loss: 3.7345\n",
      "Epoch 74/10000\n",
      "100/100 [==============================] - 0s 942us/step - loss: 4.2339 - xent_loss: 0.4995 - heat_loss: 3.7345\n",
      "Epoch 75/10000\n",
      "100/100 [==============================] - 0s 953us/step - loss: 4.2339 - xent_loss: 0.4995 - heat_loss: 3.7345\n",
      "Epoch 76/10000\n",
      "100/100 [==============================] - 0s 882us/step - loss: 4.2339 - xent_loss: 0.4994 - heat_loss: 3.7345\n",
      "Epoch 77/10000\n",
      "100/100 [==============================] - 0s 401us/step - loss: 4.2339 - xent_loss: 0.4994 - heat_loss: 3.7345\n",
      "Epoch 78/10000\n",
      "100/100 [==============================] - 0s 321us/step - loss: 4.2339 - xent_loss: 0.4994 - heat_loss: 3.7345\n",
      "Epoch 79/10000\n",
      "100/100 [==============================] - 0s 361us/step - loss: 4.2339 - xent_loss: 0.4994 - heat_loss: 3.7345\n",
      "Epoch 80/10000\n",
      "100/100 [==============================] - 0s 351us/step - loss: 4.2339 - xent_loss: 0.4994 - heat_loss: 3.7345\n",
      "Epoch 81/10000\n",
      "100/100 [==============================] - 0s 391us/step - loss: 4.2339 - xent_loss: 0.4994 - heat_loss: 3.7345\n",
      "Epoch 82/10000\n",
      "100/100 [==============================] - 0s 391us/step - loss: 4.2339 - xent_loss: 0.4994 - heat_loss: 3.7345\n",
      "Epoch 83/10000\n",
      "100/100 [==============================] - 0s 371us/step - loss: 4.2339 - xent_loss: 0.4994 - heat_loss: 3.7345\n",
      "Epoch 84/10000\n",
      "100/100 [==============================] - 0s 481us/step - loss: 4.2339 - xent_loss: 0.4994 - heat_loss: 3.7345\n",
      "Epoch 85/10000\n",
      "100/100 [==============================] - 0s 471us/step - loss: 4.2339 - xent_loss: 0.4994 - heat_loss: 3.7345\n",
      "Epoch 86/10000\n",
      "100/100 [==============================] - 0s 381us/step - loss: 4.2339 - xent_loss: 0.4994 - heat_loss: 3.7345\n",
      "Epoch 87/10000\n",
      "100/100 [==============================] - 0s 351us/step - loss: 4.2339 - xent_loss: 0.4994 - heat_loss: 3.7345\n",
      "Epoch 88/10000\n",
      "100/100 [==============================] - 0s 802us/step - loss: 4.2339 - xent_loss: 0.4994 - heat_loss: 3.7345\n",
      "Epoch 89/10000\n",
      "100/100 [==============================] - 0s 391us/step - loss: 4.2339 - xent_loss: 0.4994 - heat_loss: 3.7345\n",
      "Epoch 90/10000\n",
      "100/100 [==============================] - 0s 762us/step - loss: 4.2339 - xent_loss: 0.4994 - heat_loss: 3.7345\n",
      "Epoch 91/10000\n",
      "100/100 [==============================] - 0s 501us/step - loss: 4.2339 - xent_loss: 0.4994 - heat_loss: 3.7345\n",
      "Epoch 92/10000\n",
      "100/100 [==============================] - 0s 351us/step - loss: 4.2339 - xent_loss: 0.4994 - heat_loss: 3.7345\n",
      "Epoch 93/10000\n",
      "100/100 [==============================] - 0s 371us/step - loss: 4.2339 - xent_loss: 0.4994 - heat_loss: 3.7345\n",
      "Epoch 94/10000\n",
      "100/100 [==============================] - 0s 351us/step - loss: 4.2339 - xent_loss: 0.4994 - heat_loss: 3.7345\n",
      "Epoch 95/10000\n",
      "100/100 [==============================] - 0s 301us/step - loss: 4.2338 - xent_loss: 0.4994 - heat_loss: 3.7345\n",
      "Epoch 96/10000\n",
      "100/100 [==============================] - 0s 311us/step - loss: 4.2338 - xent_loss: 0.4994 - heat_loss: 3.7345\n",
      "Epoch 97/10000\n",
      "100/100 [==============================] - 0s 381us/step - loss: 4.2338 - xent_loss: 0.4994 - heat_loss: 3.7345\n",
      "Epoch 98/10000\n",
      "100/100 [==============================] - 0s 471us/step - loss: 4.2338 - xent_loss: 0.4994 - heat_loss: 3.7345\n",
      "Epoch 99/10000\n",
      "100/100 [==============================] - 0s 471us/step - loss: 4.2338 - xent_loss: 0.4994 - heat_loss: 3.7345\n",
      "Epoch 100/10000\n",
      "100/100 [==============================] - 0s 411us/step - loss: 4.2338 - xent_loss: 0.4994 - heat_loss: 3.7345\n",
      "Epoch 101/10000\n",
      "100/100 [==============================] - 0s 491us/step - loss: 4.2338 - xent_loss: 0.4994 - heat_loss: 3.7345\n",
      "Epoch 102/10000\n",
      "100/100 [==============================] - 0s 361us/step - loss: 4.2338 - xent_loss: 0.4993 - heat_loss: 3.7345\n",
      "Epoch 103/10000\n",
      "100/100 [==============================] - 0s 441us/step - loss: 4.2338 - xent_loss: 0.4993 - heat_loss: 3.7345\n",
      "Epoch 104/10000\n",
      "100/100 [==============================] - 0s 466us/step - loss: 4.2338 - xent_loss: 0.4993 - heat_loss: 3.7345\n",
      "Epoch 105/10000\n",
      "100/100 [==============================] - 0s 391us/step - loss: 4.2338 - xent_loss: 0.4993 - heat_loss: 3.7345\n",
      "Epoch 106/10000\n",
      "100/100 [==============================] - 0s 381us/step - loss: 4.2338 - xent_loss: 0.4993 - heat_loss: 3.7345\n",
      "Epoch 107/10000\n",
      "100/100 [==============================] - 0s 371us/step - loss: 4.2338 - xent_loss: 0.4993 - heat_loss: 3.7345\n",
      "Epoch 108/10000\n",
      "100/100 [==============================] - 0s 421us/step - loss: 4.2338 - xent_loss: 0.4993 - heat_loss: 3.7345\n",
      "Epoch 109/10000\n",
      "100/100 [==============================] - 0s 411us/step - loss: 4.2338 - xent_loss: 0.4993 - heat_loss: 3.7345\n",
      "Epoch 110/10000\n",
      "100/100 [==============================] - 0s 391us/step - loss: 4.2338 - xent_loss: 0.4993 - heat_loss: 3.7345\n",
      "Epoch 111/10000\n",
      "100/100 [==============================] - 0s 361us/step - loss: 4.2338 - xent_loss: 0.4993 - heat_loss: 3.7345\n",
      "Epoch 112/10000\n",
      "100/100 [==============================] - 0s 940us/step - loss: 4.2338 - xent_loss: 0.4993 - heat_loss: 3.7345\n",
      "Epoch 113/10000\n",
      "100/100 [==============================] - 0s 331us/step - loss: 4.2338 - xent_loss: 0.4993 - heat_loss: 3.7345\n",
      "Epoch 114/10000\n",
      "100/100 [==============================] - 0s 341us/step - loss: 4.2338 - xent_loss: 0.4993 - heat_loss: 3.7345\n",
      "Epoch 115/10000\n",
      "100/100 [==============================] - 0s 421us/step - loss: 4.2338 - xent_loss: 0.4993 - heat_loss: 3.7345\n",
      "Epoch 116/10000\n",
      "100/100 [==============================] - 0s 407us/step - loss: 4.2338 - xent_loss: 0.4993 - heat_loss: 3.7345\n",
      "Epoch 117/10000\n",
      "100/100 [==============================] - 0s 461us/step - loss: 4.2338 - xent_loss: 0.4993 - heat_loss: 3.7345\n",
      "Epoch 118/10000\n",
      "100/100 [==============================] - 0s 401us/step - loss: 4.2338 - xent_loss: 0.4993 - heat_loss: 3.7345\n",
      "Epoch 119/10000\n",
      "100/100 [==============================] - 0s 471us/step - loss: 4.2338 - xent_loss: 0.4993 - heat_loss: 3.7345\n",
      "Epoch 120/10000\n",
      "100/100 [==============================] - 0s 371us/step - loss: 4.2338 - xent_loss: 0.4993 - heat_loss: 3.7345\n",
      "Epoch 121/10000\n",
      "100/100 [==============================] - 0s 401us/step - loss: 4.2338 - xent_loss: 0.4993 - heat_loss: 3.7345\n",
      "Epoch 122/10000\n",
      "100/100 [==============================] - 0s 923us/step - loss: 4.2337 - xent_loss: 0.4993 - heat_loss: 3.7345\n",
      "Epoch 123/10000\n",
      "100/100 [==============================] - 0s 351us/step - loss: 4.2337 - xent_loss: 0.4993 - heat_loss: 3.7345\n",
      "Epoch 124/10000\n",
      "100/100 [==============================] - 0s 993us/step - loss: 4.2337 - xent_loss: 0.4993 - heat_loss: 3.7345\n",
      "Epoch 125/10000\n",
      "100/100 [==============================] - 0s 341us/step - loss: 4.2337 - xent_loss: 0.4993 - heat_loss: 3.7345\n",
      "Epoch 126/10000\n",
      "100/100 [==============================] - 0s 865us/step - loss: 4.2337 - xent_loss: 0.4993 - heat_loss: 3.7345\n",
      "Epoch 127/10000\n",
      "100/100 [==============================] - 0s 391us/step - loss: 4.2337 - xent_loss: 0.4993 - heat_loss: 3.7345\n",
      "Epoch 128/10000\n",
      "100/100 [==============================] - 0s 873us/step - loss: 4.2337 - xent_loss: 0.4992 - heat_loss: 3.7345\n",
      "Epoch 129/10000\n",
      "100/100 [==============================] - 0s 800us/step - loss: 4.2337 - xent_loss: 0.4992 - heat_loss: 3.7345\n",
      "Epoch 130/10000\n",
      "100/100 [==============================] - 0s 300us/step - loss: 4.2337 - xent_loss: 0.4992 - heat_loss: 3.7345\n",
      "Epoch 131/10000\n",
      "100/100 [==============================] - 0s 900us/step - loss: 4.2337 - xent_loss: 0.4992 - heat_loss: 3.7345\n",
      "Epoch 132/10000\n",
      "100/100 [==============================] - 0s 471us/step - loss: 4.2337 - xent_loss: 0.4992 - heat_loss: 3.7345\n",
      "Epoch 133/10000\n",
      "100/100 [==============================] - 0s 411us/step - loss: 4.2337 - xent_loss: 0.4992 - heat_loss: 3.7345\n",
      "Epoch 134/10000\n",
      "100/100 [==============================] - 0s 381us/step - loss: 4.2337 - xent_loss: 0.4992 - heat_loss: 3.7345\n",
      "Epoch 135/10000\n",
      "100/100 [==============================] - 0s 461us/step - loss: 4.2337 - xent_loss: 0.4992 - heat_loss: 3.7345\n",
      "Epoch 136/10000\n",
      "100/100 [==============================] - 0s 391us/step - loss: 4.2337 - xent_loss: 0.4992 - heat_loss: 3.7345\n",
      "Epoch 137/10000\n",
      "100/100 [==============================] - 0s 391us/step - loss: 4.2337 - xent_loss: 0.4992 - heat_loss: 3.7345\n",
      "Epoch 138/10000\n",
      "100/100 [==============================] - 0s 421us/step - loss: 4.2337 - xent_loss: 0.4992 - heat_loss: 3.7345\n",
      "Epoch 139/10000\n",
      "100/100 [==============================] - 0s 341us/step - loss: 4.2337 - xent_loss: 0.4992 - heat_loss: 3.7345\n",
      "Epoch 140/10000\n",
      "100/100 [==============================] - 0s 331us/step - loss: 4.2337 - xent_loss: 0.4992 - heat_loss: 3.7345\n",
      "Epoch 141/10000\n",
      "100/100 [==============================] - 0s 331us/step - loss: 4.2337 - xent_loss: 0.4992 - heat_loss: 3.7345\n",
      "Epoch 142/10000\n",
      "100/100 [==============================] - 0s 371us/step - loss: 4.2337 - xent_loss: 0.4992 - heat_loss: 3.7345\n",
      "Epoch 143/10000\n",
      "100/100 [==============================] - 0s 371us/step - loss: 4.2337 - xent_loss: 0.4992 - heat_loss: 3.7345\n",
      "Epoch 144/10000\n",
      "100/100 [==============================] - 0s 351us/step - loss: 4.2337 - xent_loss: 0.4992 - heat_loss: 3.7345\n",
      "Epoch 145/10000\n",
      "100/100 [==============================] - 0s 431us/step - loss: 4.2337 - xent_loss: 0.4992 - heat_loss: 3.7345\n",
      "Epoch 146/10000\n",
      "100/100 [==============================] - 0s 371us/step - loss: 4.2337 - xent_loss: 0.4992 - heat_loss: 3.7345\n",
      "Epoch 147/10000\n",
      "100/100 [==============================] - 0s 351us/step - loss: 4.2337 - xent_loss: 0.4992 - heat_loss: 3.7345\n",
      "Epoch 148/10000\n",
      "100/100 [==============================] - 0s 300us/step - loss: 4.2337 - xent_loss: 0.4992 - heat_loss: 3.7345\n",
      "Epoch 149/10000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.2337 - xent_loss: 0.4992 - heat_loss: 3.7345\n",
      "Epoch 150/10000\n",
      "100/100 [==============================] - 0s 461us/step - loss: 4.2336 - xent_loss: 0.4992 - heat_loss: 3.7345\n",
      "Epoch 151/10000\n",
      "100/100 [==============================] - 0s 875us/step - loss: 4.2336 - xent_loss: 0.4992 - heat_loss: 3.7345\n",
      "Epoch 152/10000\n",
      "100/100 [==============================] - 0s 832us/step - loss: 4.2336 - xent_loss: 0.4992 - heat_loss: 3.7345\n",
      "Epoch 153/10000\n",
      "100/100 [==============================] - 0s 381us/step - loss: 4.2336 - xent_loss: 0.4992 - heat_loss: 3.7345\n",
      "Epoch 154/10000\n",
      "100/100 [==============================] - 0s 246us/step - loss: 4.2336 - xent_loss: 0.4992 - heat_loss: 3.7345\n",
      "Epoch 155/10000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.2336 - xent_loss: 0.4991 - heat_loss: 3.7345\n",
      "Epoch 156/10000\n",
      "100/100 [==============================] - 0s 341us/step - loss: 4.2336 - xent_loss: 0.4991 - heat_loss: 3.7345\n",
      "Epoch 157/10000\n",
      "100/100 [==============================] - 0s 311us/step - loss: 4.2336 - xent_loss: 0.4991 - heat_loss: 3.7345\n",
      "Epoch 158/10000\n",
      "100/100 [==============================] - 0s 411us/step - loss: 4.2336 - xent_loss: 0.4991 - heat_loss: 3.7345\n",
      "Epoch 159/10000\n",
      "100/100 [==============================] - 0s 411us/step - loss: 4.2336 - xent_loss: 0.4991 - heat_loss: 3.7345\n",
      "Epoch 160/10000\n",
      "100/100 [==============================] - 0s 331us/step - loss: 4.2336 - xent_loss: 0.4991 - heat_loss: 3.7345\n",
      "Epoch 161/10000\n",
      "100/100 [==============================] - 0s 391us/step - loss: 4.2336 - xent_loss: 0.4991 - heat_loss: 3.7345\n",
      "Epoch 162/10000\n",
      "100/100 [==============================] - 0s 441us/step - loss: 4.2336 - xent_loss: 0.4991 - heat_loss: 3.7345\n",
      "Epoch 163/10000\n",
      "100/100 [==============================] - 0s 401us/step - loss: 4.2336 - xent_loss: 0.4991 - heat_loss: 3.7345\n",
      "Epoch 164/10000\n",
      "100/100 [==============================] - 0s 400us/step - loss: 4.2336 - xent_loss: 0.4991 - heat_loss: 3.7345\n",
      "Epoch 165/10000\n",
      "100/100 [==============================] - 0s 892us/step - loss: 4.2336 - xent_loss: 0.4991 - heat_loss: 3.7345\n",
      "Epoch 166/10000\n",
      "100/100 [==============================] - 0s 391us/step - loss: 4.2336 - xent_loss: 0.4991 - heat_loss: 3.7345\n",
      "Epoch 167/10000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.2336 - xent_loss: 0.4991 - heat_loss: 3.7345\n",
      "Epoch 168/10000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.2336 - xent_loss: 0.4991 - heat_loss: 3.7345\n",
      "Epoch 169/10000\n",
      "100/100 [==============================] - 0s 393us/step - loss: 4.2336 - xent_loss: 0.4991 - heat_loss: 3.7345\n",
      "Epoch 170/10000\n",
      "100/100 [==============================] - 0s 300us/step - loss: 4.2336 - xent_loss: 0.4991 - heat_loss: 3.7345\n",
      "Epoch 171/10000\n",
      "100/100 [==============================] - 0s 300us/step - loss: 4.2336 - xent_loss: 0.4991 - heat_loss: 3.7345\n",
      "Epoch 172/10000\n",
      "100/100 [==============================] - 0s 400us/step - loss: 4.2336 - xent_loss: 0.4991 - heat_loss: 3.7345\n",
      "Epoch 173/10000\n",
      "100/100 [==============================] - 0s 402us/step - loss: 4.2336 - xent_loss: 0.4991 - heat_loss: 3.7345\n",
      "Epoch 174/10000\n",
      "100/100 [==============================] - 0s 413us/step - loss: 4.2336 - xent_loss: 0.4991 - heat_loss: 3.7345\n",
      "Epoch 175/10000\n",
      "100/100 [==============================] - 0s 491us/step - loss: 4.2336 - xent_loss: 0.4991 - heat_loss: 3.7345\n",
      "Epoch 176/10000\n",
      "100/100 [==============================] - 0s 491us/step - loss: 4.2335 - xent_loss: 0.4991 - heat_loss: 3.7345\n",
      "Epoch 177/10000\n",
      "100/100 [==============================] - 0s 411us/step - loss: 4.2335 - xent_loss: 0.4991 - heat_loss: 3.7345\n",
      "Epoch 178/10000\n",
      "100/100 [==============================] - 0s 259us/step - loss: 4.2335 - xent_loss: 0.4991 - heat_loss: 3.7345\n",
      "Epoch 179/10000\n",
      "100/100 [==============================] - 0s 400us/step - loss: 4.2335 - xent_loss: 0.4991 - heat_loss: 3.7345\n",
      "Epoch 180/10000\n",
      "100/100 [==============================] - 0s 873us/step - loss: 4.2335 - xent_loss: 0.4991 - heat_loss: 3.7345\n",
      "Epoch 181/10000\n",
      "100/100 [==============================] - 0s 852us/step - loss: 4.2335 - xent_loss: 0.4991 - heat_loss: 3.7345\n",
      "Epoch 182/10000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.2335 - xent_loss: 0.4990 - heat_loss: 3.7345\n",
      "Epoch 183/10000\n",
      "100/100 [==============================] - 0s 371us/step - loss: 4.2335 - xent_loss: 0.4990 - heat_loss: 3.7345\n",
      "Epoch 184/10000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.2335 - xent_loss: 0.4990 - heat_loss: 3.7345\n",
      "Epoch 185/10000\n",
      "100/100 [==============================] - 0s 331us/step - loss: 4.2335 - xent_loss: 0.4990 - heat_loss: 3.7345\n",
      "Epoch 186/10000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.2335 - xent_loss: 0.4990 - heat_loss: 3.7345\n",
      "Epoch 187/10000\n",
      "100/100 [==============================] - 0s 361us/step - loss: 4.2335 - xent_loss: 0.4990 - heat_loss: 3.7345\n",
      "Epoch 188/10000\n",
      "100/100 [==============================] - 0s 371us/step - loss: 4.2335 - xent_loss: 0.4990 - heat_loss: 3.7345\n",
      "Epoch 189/10000\n",
      "100/100 [==============================] - 0s 441us/step - loss: 4.2335 - xent_loss: 0.4990 - heat_loss: 3.7345\n",
      "Epoch 190/10000\n",
      "100/100 [==============================] - 0s 341us/step - loss: 4.2335 - xent_loss: 0.4990 - heat_loss: 3.7345\n",
      "Epoch 191/10000\n",
      "100/100 [==============================] - 0s 391us/step - loss: 4.2335 - xent_loss: 0.4990 - heat_loss: 3.7345\n",
      "Epoch 192/10000\n",
      "100/100 [==============================] - 0s 331us/step - loss: 4.2335 - xent_loss: 0.4990 - heat_loss: 3.7345\n",
      "Epoch 193/10000\n",
      "100/100 [==============================] - 0s 471us/step - loss: 4.2335 - xent_loss: 0.4990 - heat_loss: 3.7345\n",
      "Epoch 194/10000\n",
      "100/100 [==============================] - 0s 401us/step - loss: 4.2335 - xent_loss: 0.4990 - heat_loss: 3.7345\n",
      "Epoch 195/10000\n",
      "100/100 [==============================] - 0s 314us/step - loss: 4.2335 - xent_loss: 0.4990 - heat_loss: 3.7345\n",
      "Epoch 196/10000\n",
      "100/100 [==============================] - 0s 800us/step - loss: 4.2335 - xent_loss: 0.4990 - heat_loss: 3.7345\n",
      "Epoch 197/10000\n",
      "100/100 [==============================] - 0s 877us/step - loss: 4.2335 - xent_loss: 0.4990 - heat_loss: 3.7345\n",
      "Epoch 198/10000\n",
      "100/100 [==============================] - 0s 875us/step - loss: 4.2335 - xent_loss: 0.4990 - heat_loss: 3.7345\n",
      "Epoch 199/10000\n",
      "100/100 [==============================] - 0s 846us/step - loss: 4.2335 - xent_loss: 0.4990 - heat_loss: 3.7345\n",
      "Epoch 200/10000\n",
      "100/100 [==============================] - 0s 900us/step - loss: 4.2335 - xent_loss: 0.4990 - heat_loss: 3.7345\n",
      "Epoch 201/10000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.2334 - xent_loss: 0.4990 - heat_loss: 3.7345\n",
      "Epoch 202/10000\n",
      "100/100 [==============================] - 0s 400us/step - loss: 4.2334 - xent_loss: 0.4990 - heat_loss: 3.7345\n",
      "Epoch 203/10000\n",
      "100/100 [==============================] - 0s 328us/step - loss: 4.2334 - xent_loss: 0.4990 - heat_loss: 3.7345\n",
      "Epoch 204/10000\n",
      "100/100 [==============================] - 0s 800us/step - loss: 4.2334 - xent_loss: 0.4990 - heat_loss: 3.7345\n",
      "Epoch 205/10000\n",
      "100/100 [==============================] - 0s 800us/step - loss: 4.2334 - xent_loss: 0.4990 - heat_loss: 3.7345\n",
      "Epoch 206/10000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.2334 - xent_loss: 0.4990 - heat_loss: 3.7345\n",
      "Epoch 207/10000\n",
      "100/100 [==============================] - 0s 722us/step - loss: 4.2334 - xent_loss: 0.4990 - heat_loss: 3.7345\n",
      "Epoch 208/10000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.2334 - xent_loss: 0.4989 - heat_loss: 3.7345\n",
      "Epoch 209/10000\n",
      "100/100 [==============================] - 0s 331us/step - loss: 4.2334 - xent_loss: 0.4989 - heat_loss: 3.7345\n",
      "Epoch 210/10000\n",
      "100/100 [==============================] - 0s 314us/step - loss: 4.2334 - xent_loss: 0.4989 - heat_loss: 3.7345\n",
      "Epoch 211/10000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.2334 - xent_loss: 0.4989 - heat_loss: 3.7345\n",
      "Epoch 212/10000\n",
      "100/100 [==============================] - 0s 400us/step - loss: 4.2334 - xent_loss: 0.4989 - heat_loss: 3.7345\n",
      "Epoch 213/10000\n",
      "100/100 [==============================] - 0s 600us/step - loss: 4.2334 - xent_loss: 0.4989 - heat_loss: 3.7345\n",
      "Epoch 214/10000\n",
      "100/100 [==============================] - 0s 848us/step - loss: 4.2334 - xent_loss: 0.4989 - heat_loss: 3.7345\n",
      "Epoch 215/10000\n",
      "100/100 [==============================] - 0s 900us/step - loss: 4.2334 - xent_loss: 0.4989 - heat_loss: 3.7345\n",
      "Epoch 216/10000\n",
      "100/100 [==============================] - 0s 535us/step - loss: 4.2334 - xent_loss: 0.4989 - heat_loss: 3.7345\n",
      "Epoch 217/10000\n",
      "100/100 [==============================] - 0s 371us/step - loss: 4.2334 - xent_loss: 0.4989 - heat_loss: 3.7345\n",
      "Epoch 218/10000\n",
      "100/100 [==============================] - 0s 471us/step - loss: 4.2334 - xent_loss: 0.4989 - heat_loss: 3.7345\n",
      "Epoch 219/10000\n",
      "100/100 [==============================] - 0s 401us/step - loss: 4.2334 - xent_loss: 0.4989 - heat_loss: 3.7345\n",
      "Epoch 220/10000\n",
      "100/100 [==============================] - 0s 381us/step - loss: 4.2334 - xent_loss: 0.4989 - heat_loss: 3.7345\n",
      "Epoch 221/10000\n",
      "100/100 [==============================] - 0s 361us/step - loss: 4.2334 - xent_loss: 0.4989 - heat_loss: 3.7345\n",
      "Epoch 222/10000\n",
      "100/100 [==============================] - 0s 298us/step - loss: 4.2334 - xent_loss: 0.4989 - heat_loss: 3.7345\n",
      "Epoch 223/10000\n",
      "100/100 [==============================] - 0s 872us/step - loss: 4.2334 - xent_loss: 0.4989 - heat_loss: 3.7345\n",
      "Epoch 224/10000\n",
      "100/100 [==============================] - 0s 471us/step - loss: 4.2334 - xent_loss: 0.4989 - heat_loss: 3.7345\n",
      "Epoch 225/10000\n",
      "100/100 [==============================] - 0s 371us/step - loss: 4.2334 - xent_loss: 0.4989 - heat_loss: 3.7345\n",
      "Epoch 226/10000\n",
      "100/100 [==============================] - 0s 331us/step - loss: 4.2334 - xent_loss: 0.4989 - heat_loss: 3.7345\n",
      "Epoch 227/10000\n",
      "100/100 [==============================] - 0s 331us/step - loss: 4.2334 - xent_loss: 0.4989 - heat_loss: 3.7345\n",
      "Epoch 228/10000\n",
      "100/100 [==============================] - 0s 341us/step - loss: 4.2334 - xent_loss: 0.4989 - heat_loss: 3.7345\n",
      "Epoch 229/10000\n",
      "100/100 [==============================] - 0s 321us/step - loss: 4.2333 - xent_loss: 0.4989 - heat_loss: 3.7345\n",
      "Epoch 230/10000\n",
      "100/100 [==============================] - 0s 296us/step - loss: 4.2333 - xent_loss: 0.4989 - heat_loss: 3.7345\n",
      "Epoch 231/10000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.2333 - xent_loss: 0.4989 - heat_loss: 3.7345\n",
      "Epoch 232/10000\n",
      "100/100 [==============================] - 0s 521us/step - loss: 4.2333 - xent_loss: 0.4989 - heat_loss: 3.7345\n",
      "Epoch 233/10000\n",
      "100/100 [==============================] - 0s 531us/step - loss: 4.2333 - xent_loss: 0.4989 - heat_loss: 3.7345\n",
      "Epoch 234/10000\n",
      "100/100 [==============================] - 0s 521us/step - loss: 4.2333 - xent_loss: 0.4988 - heat_loss: 3.7345\n",
      "Epoch 235/10000\n",
      "100/100 [==============================] - 0s 527us/step - loss: 4.2333 - xent_loss: 0.4988 - heat_loss: 3.7345\n",
      "Epoch 236/10000\n",
      "100/100 [==============================] - 0s 463us/step - loss: 4.2333 - xent_loss: 0.4988 - heat_loss: 3.7345\n",
      "Epoch 237/10000\n",
      "100/100 [==============================] - 0s 355us/step - loss: 4.2333 - xent_loss: 0.4988 - heat_loss: 3.7345\n",
      "Epoch 238/10000\n",
      "100/100 [==============================] - 0s 371us/step - loss: 4.2333 - xent_loss: 0.4988 - heat_loss: 3.7345\n",
      "Epoch 239/10000\n",
      "100/100 [==============================] - 0s 393us/step - loss: 4.2333 - xent_loss: 0.4988 - heat_loss: 3.7345\n",
      "Epoch 240/10000\n",
      "100/100 [==============================] - 0s 900us/step - loss: 4.2333 - xent_loss: 0.4988 - heat_loss: 3.7345\n",
      "Epoch 241/10000\n",
      "100/100 [==============================] - 0s 900us/step - loss: 4.2333 - xent_loss: 0.4988 - heat_loss: 3.7345\n",
      "Epoch 242/10000\n",
      "100/100 [==============================] - 0s 600us/step - loss: 4.2333 - xent_loss: 0.4988 - heat_loss: 3.7345\n",
      "Epoch 243/10000\n",
      "100/100 [==============================] - 0s 300us/step - loss: 4.2333 - xent_loss: 0.4988 - heat_loss: 3.7345\n",
      "Epoch 244/10000\n",
      "100/100 [==============================] - 0s 300us/step - loss: 4.2333 - xent_loss: 0.4988 - heat_loss: 3.7345\n",
      "Epoch 245/10000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.2333 - xent_loss: 0.4988 - heat_loss: 3.7345\n",
      "Epoch 246/10000\n",
      "100/100 [==============================] - 0s 400us/step - loss: 4.2333 - xent_loss: 0.4988 - heat_loss: 3.7345\n",
      "Epoch 247/10000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.2333 - xent_loss: 0.4988 - heat_loss: 3.7345\n",
      "Epoch 248/10000\n",
      "100/100 [==============================] - 0s 351us/step - loss: 4.2333 - xent_loss: 0.4988 - heat_loss: 3.7345\n",
      "Epoch 249/10000\n",
      "100/100 [==============================] - 0s 321us/step - loss: 4.2333 - xent_loss: 0.4988 - heat_loss: 3.7345\n",
      "Epoch 250/10000\n",
      "100/100 [==============================] - 0s 331us/step - loss: 4.2333 - xent_loss: 0.4988 - heat_loss: 3.7345\n",
      "Epoch 251/10000\n",
      "100/100 [==============================] - 0s 351us/step - loss: 4.2333 - xent_loss: 0.4988 - heat_loss: 3.7345\n",
      "Epoch 252/10000\n",
      "100/100 [==============================] - 0s 341us/step - loss: 4.2333 - xent_loss: 0.4988 - heat_loss: 3.7345\n",
      "Epoch 253/10000\n",
      "100/100 [==============================] - 0s 371us/step - loss: 4.2333 - xent_loss: 0.4988 - heat_loss: 3.7345\n",
      "Epoch 254/10000\n",
      "100/100 [==============================] - 0s 381us/step - loss: 4.2332 - xent_loss: 0.4988 - heat_loss: 3.7345\n",
      "Epoch 255/10000\n",
      "100/100 [==============================] - 0s 351us/step - loss: 4.2332 - xent_loss: 0.4988 - heat_loss: 3.7345\n",
      "Epoch 256/10000\n",
      "100/100 [==============================] - 0s 769us/step - loss: 4.2332 - xent_loss: 0.4988 - heat_loss: 3.7345\n",
      "Epoch 257/10000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.2332 - xent_loss: 0.4988 - heat_loss: 3.7345\n",
      "Epoch 258/10000\n",
      "100/100 [==============================] - 0s 351us/step - loss: 4.2332 - xent_loss: 0.4988 - heat_loss: 3.7345\n",
      "Epoch 259/10000\n",
      "100/100 [==============================] - 0s 291us/step - loss: 4.2332 - xent_loss: 0.4987 - heat_loss: 3.7345\n",
      "Epoch 260/10000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.2332 - xent_loss: 0.4987 - heat_loss: 3.7345\n",
      "Epoch 261/10000\n",
      "100/100 [==============================] - 0s 722us/step - loss: 4.2332 - xent_loss: 0.4987 - heat_loss: 3.7345\n",
      "Epoch 262/10000\n",
      "100/100 [==============================] - 0s 481us/step - loss: 4.2332 - xent_loss: 0.4987 - heat_loss: 3.7345\n",
      "Epoch 263/10000\n",
      "100/100 [==============================] - 0s 421us/step - loss: 4.2332 - xent_loss: 0.4987 - heat_loss: 3.7345\n",
      "Epoch 264/10000\n",
      "100/100 [==============================] - 0s 381us/step - loss: 4.2332 - xent_loss: 0.4987 - heat_loss: 3.7345\n",
      "Epoch 265/10000\n",
      "100/100 [==============================] - 0s 361us/step - loss: 4.2332 - xent_loss: 0.4987 - heat_loss: 3.7345\n",
      "Epoch 266/10000\n",
      "100/100 [==============================] - 0s 511us/step - loss: 4.2332 - xent_loss: 0.4987 - heat_loss: 3.7345\n",
      "Epoch 267/10000\n",
      "100/100 [==============================] - 0s 451us/step - loss: 4.2332 - xent_loss: 0.4987 - heat_loss: 3.7345\n",
      "Epoch 268/10000\n",
      "100/100 [==============================] - 0s 501us/step - loss: 4.2332 - xent_loss: 0.4987 - heat_loss: 3.7345\n",
      "Epoch 269/10000\n",
      "100/100 [==============================] - 0s 451us/step - loss: 4.2332 - xent_loss: 0.4987 - heat_loss: 3.7345\n",
      "Epoch 270/10000\n",
      "100/100 [==============================] - 0s 331us/step - loss: 4.2332 - xent_loss: 0.4987 - heat_loss: 3.7345\n",
      "Epoch 271/10000\n",
      "100/100 [==============================] - 0s 341us/step - loss: 4.2332 - xent_loss: 0.4987 - heat_loss: 3.7345\n",
      "Epoch 272/10000\n",
      "100/100 [==============================] - 0s 310us/step - loss: 4.2332 - xent_loss: 0.4987 - heat_loss: 3.7345\n",
      "Epoch 273/10000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.2332 - xent_loss: 0.4987 - heat_loss: 3.7345\n",
      "Epoch 274/10000\n",
      "100/100 [==============================] - 0s 351us/step - loss: 4.2332 - xent_loss: 0.4987 - heat_loss: 3.7345\n",
      "Epoch 275/10000\n",
      "100/100 [==============================] - 0s 361us/step - loss: 4.2332 - xent_loss: 0.4987 - heat_loss: 3.7345\n",
      "Epoch 276/10000\n",
      "100/100 [==============================] - 0s 391us/step - loss: 4.2332 - xent_loss: 0.4987 - heat_loss: 3.7345\n",
      "Epoch 277/10000\n",
      "100/100 [==============================] - 0s 461us/step - loss: 4.2332 - xent_loss: 0.4987 - heat_loss: 3.7345\n",
      "Epoch 278/10000\n",
      "100/100 [==============================] - 0s 371us/step - loss: 4.2332 - xent_loss: 0.4987 - heat_loss: 3.7345\n",
      "Epoch 279/10000\n",
      "100/100 [==============================] - 0s 283us/step - loss: 4.2331 - xent_loss: 0.4987 - heat_loss: 3.7345\n",
      "Epoch 280/10000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.2331 - xent_loss: 0.4987 - heat_loss: 3.7345\n",
      "Epoch 281/10000\n",
      "100/100 [==============================] - 0s 341us/step - loss: 4.2331 - xent_loss: 0.4987 - heat_loss: 3.7345\n",
      "Epoch 282/10000\n",
      "100/100 [==============================] - 0s 341us/step - loss: 4.2331 - xent_loss: 0.4987 - heat_loss: 3.7345\n",
      "Epoch 283/10000\n",
      "100/100 [==============================] - 0s 927us/step - loss: 4.2331 - xent_loss: 0.4987 - heat_loss: 3.7345\n",
      "Epoch 284/10000\n",
      "100/100 [==============================] - 0s 700us/step - loss: 4.2331 - xent_loss: 0.4986 - heat_loss: 3.7345\n",
      "Epoch 285/10000\n",
      "100/100 [==============================] - 0s 900us/step - loss: 4.2331 - xent_loss: 0.4986 - heat_loss: 3.7345\n",
      "Epoch 286/10000\n",
      "100/100 [==============================] - 0s 879us/step - loss: 4.2331 - xent_loss: 0.4986 - heat_loss: 3.7345\n",
      "Epoch 287/10000\n",
      "100/100 [==============================] - 0s 300us/step - loss: 4.2331 - xent_loss: 0.4986 - heat_loss: 3.7345\n",
      "Epoch 288/10000\n",
      "100/100 [==============================] - 0s 481us/step - loss: 4.2331 - xent_loss: 0.4986 - heat_loss: 3.7345\n",
      "Epoch 289/10000\n",
      "100/100 [==============================] - 0s 361us/step - loss: 4.2331 - xent_loss: 0.4986 - heat_loss: 3.7345\n",
      "Epoch 290/10000\n",
      "100/100 [==============================] - 0s 501us/step - loss: 4.2331 - xent_loss: 0.4986 - heat_loss: 3.7345\n",
      "Epoch 291/10000\n",
      "100/100 [==============================] - 0s 489us/step - loss: 4.2331 - xent_loss: 0.4986 - heat_loss: 3.7345\n",
      "Epoch 292/10000\n",
      "100/100 [==============================] - 0s 391us/step - loss: 4.2331 - xent_loss: 0.4986 - heat_loss: 3.7345\n",
      "Epoch 293/10000\n",
      "100/100 [==============================] - 0s 401us/step - loss: 4.2331 - xent_loss: 0.4986 - heat_loss: 3.7345\n",
      "Epoch 294/10000\n",
      "100/100 [==============================] - 0s 401us/step - loss: 4.2331 - xent_loss: 0.4986 - heat_loss: 3.7345\n",
      "Epoch 295/10000\n",
      "100/100 [==============================] - 0s 471us/step - loss: 4.2331 - xent_loss: 0.4986 - heat_loss: 3.7345\n",
      "Epoch 296/10000\n",
      "100/100 [==============================] - 0s 411us/step - loss: 4.2331 - xent_loss: 0.4986 - heat_loss: 3.7345\n",
      "Epoch 297/10000\n",
      "100/100 [==============================] - 0s 401us/step - loss: 4.2331 - xent_loss: 0.4986 - heat_loss: 3.7345\n",
      "Epoch 298/10000\n",
      "100/100 [==============================] - 0s 421us/step - loss: 4.2331 - xent_loss: 0.4986 - heat_loss: 3.7345\n",
      "Epoch 299/10000\n",
      "100/100 [==============================] - 0s 511us/step - loss: 4.2331 - xent_loss: 0.4986 - heat_loss: 3.7345\n",
      "Epoch 300/10000\n",
      "100/100 [==============================] - 0s 293us/step - loss: 4.2331 - xent_loss: 0.4986 - heat_loss: 3.7345\n",
      "Epoch 301/10000\n",
      "100/100 [==============================] - 0s 421us/step - loss: 4.2331 - xent_loss: 0.4986 - heat_loss: 3.7345\n",
      "Epoch 302/10000\n",
      "100/100 [==============================] - 0s 351us/step - loss: 4.2331 - xent_loss: 0.4986 - heat_loss: 3.7345\n",
      "Epoch 303/10000\n",
      "100/100 [==============================] - 0s 525us/step - loss: 4.2330 - xent_loss: 0.4986 - heat_loss: 3.7345\n",
      "Epoch 304/10000\n",
      "100/100 [==============================] - 0s 491us/step - loss: 4.2330 - xent_loss: 0.4986 - heat_loss: 3.7345\n",
      "Epoch 305/10000\n",
      "100/100 [==============================] - 0s 381us/step - loss: 4.2330 - xent_loss: 0.4986 - heat_loss: 3.7345\n",
      "Epoch 306/10000\n",
      "100/100 [==============================] - 0s 401us/step - loss: 4.2330 - xent_loss: 0.4986 - heat_loss: 3.7345\n",
      "Epoch 307/10000\n",
      "100/100 [==============================] - 0s 511us/step - loss: 4.2330 - xent_loss: 0.4986 - heat_loss: 3.7345\n",
      "Epoch 308/10000\n",
      "100/100 [==============================] - 0s 461us/step - loss: 4.2330 - xent_loss: 0.4986 - heat_loss: 3.7345\n",
      "Epoch 309/10000\n",
      "100/100 [==============================] - 0s 311us/step - loss: 4.2330 - xent_loss: 0.4985 - heat_loss: 3.7345\n",
      "Epoch 310/10000\n",
      "100/100 [==============================] - 0s 371us/step - loss: 4.2330 - xent_loss: 0.4985 - heat_loss: 3.7345\n",
      "Epoch 311/10000\n",
      "100/100 [==============================] - 0s 311us/step - loss: 4.2330 - xent_loss: 0.4985 - heat_loss: 3.7345\n",
      "Epoch 312/10000\n",
      "100/100 [==============================] - 0s 391us/step - loss: 4.2330 - xent_loss: 0.4985 - heat_loss: 3.7345\n",
      "Epoch 313/10000\n",
      "100/100 [==============================] - 0s 301us/step - loss: 4.2330 - xent_loss: 0.4985 - heat_loss: 3.7345\n",
      "Epoch 314/10000\n",
      "100/100 [==============================] - 0s 481us/step - loss: 4.2330 - xent_loss: 0.4985 - heat_loss: 3.7345\n",
      "Epoch 315/10000\n",
      "100/100 [==============================] - 0s 331us/step - loss: 4.2330 - xent_loss: 0.4985 - heat_loss: 3.7345\n",
      "Epoch 316/10000\n",
      "100/100 [==============================] - 0s 321us/step - loss: 4.2330 - xent_loss: 0.4985 - heat_loss: 3.7345\n",
      "Epoch 317/10000\n",
      "100/100 [==============================] - 0s 321us/step - loss: 4.2330 - xent_loss: 0.4985 - heat_loss: 3.7345\n",
      "Epoch 318/10000\n",
      "100/100 [==============================] - 0s 321us/step - loss: 4.2330 - xent_loss: 0.4985 - heat_loss: 3.7345\n",
      "Epoch 319/10000\n",
      "100/100 [==============================] - 0s 331us/step - loss: 4.2330 - xent_loss: 0.4985 - heat_loss: 3.7345\n",
      "Epoch 320/10000\n",
      "100/100 [==============================] - 0s 301us/step - loss: 4.2330 - xent_loss: 0.4985 - heat_loss: 3.7345\n",
      "Epoch 321/10000\n",
      "100/100 [==============================] - 0s 411us/step - loss: 4.2330 - xent_loss: 0.4985 - heat_loss: 3.7345\n",
      "Epoch 322/10000\n",
      "100/100 [==============================] - 0s 301us/step - loss: 4.2330 - xent_loss: 0.4985 - heat_loss: 3.7345\n",
      "Epoch 323/10000\n",
      "100/100 [==============================] - 0s 421us/step - loss: 4.2330 - xent_loss: 0.4985 - heat_loss: 3.7345\n",
      "Epoch 324/10000\n",
      "100/100 [==============================] - 0s 321us/step - loss: 4.2330 - xent_loss: 0.4985 - heat_loss: 3.7345\n",
      "Epoch 325/10000\n",
      "100/100 [==============================] - 0s 371us/step - loss: 4.2330 - xent_loss: 0.4985 - heat_loss: 3.7345\n",
      "Epoch 326/10000\n",
      "100/100 [==============================] - 0s 311us/step - loss: 4.2329 - xent_loss: 0.4985 - heat_loss: 3.7345\n",
      "Epoch 327/10000\n",
      "100/100 [==============================] - 0s 360us/step - loss: 4.2329 - xent_loss: 0.4985 - heat_loss: 3.7345\n",
      "Epoch 328/10000\n",
      "100/100 [==============================] - 0s 311us/step - loss: 4.2329 - xent_loss: 0.4985 - heat_loss: 3.7345\n",
      "Epoch 329/10000\n",
      "100/100 [==============================] - 0s 371us/step - loss: 4.2329 - xent_loss: 0.4985 - heat_loss: 3.7345\n",
      "Epoch 330/10000\n",
      "100/100 [==============================] - 0s 351us/step - loss: 4.2329 - xent_loss: 0.4985 - heat_loss: 3.7345\n",
      "Epoch 331/10000\n",
      "100/100 [==============================] - 0s 321us/step - loss: 4.2329 - xent_loss: 0.4985 - heat_loss: 3.7345\n",
      "Epoch 332/10000\n",
      "100/100 [==============================] - 0s 371us/step - loss: 4.2329 - xent_loss: 0.4984 - heat_loss: 3.7345\n",
      "Epoch 333/10000\n",
      "100/100 [==============================] - 0s 301us/step - loss: 4.2329 - xent_loss: 0.4984 - heat_loss: 3.7345\n",
      "Epoch 334/10000\n",
      "100/100 [==============================] - 0s 311us/step - loss: 4.2329 - xent_loss: 0.4984 - heat_loss: 3.7345\n",
      "Epoch 335/10000\n",
      "100/100 [==============================] - 0s 331us/step - loss: 4.2329 - xent_loss: 0.4984 - heat_loss: 3.7345\n",
      "Epoch 336/10000\n",
      "100/100 [==============================] - 0s 311us/step - loss: 4.2329 - xent_loss: 0.4984 - heat_loss: 3.7345\n",
      "Epoch 337/10000\n",
      "100/100 [==============================] - 0s 331us/step - loss: 4.2329 - xent_loss: 0.4984 - heat_loss: 3.7345\n",
      "Epoch 338/10000\n",
      "100/100 [==============================] - 0s 291us/step - loss: 4.2329 - xent_loss: 0.4984 - heat_loss: 3.7345\n",
      "Epoch 339/10000\n",
      "100/100 [==============================] - 0s 321us/step - loss: 4.2329 - xent_loss: 0.4984 - heat_loss: 3.7345\n",
      "Epoch 340/10000\n",
      "100/100 [==============================] - 0s 311us/step - loss: 4.2329 - xent_loss: 0.4984 - heat_loss: 3.7345\n",
      "Epoch 341/10000\n",
      "100/100 [==============================] - 0s 411us/step - loss: 4.2329 - xent_loss: 0.4984 - heat_loss: 3.7345\n",
      "Epoch 342/10000\n",
      "100/100 [==============================] - 0s 311us/step - loss: 4.2329 - xent_loss: 0.4984 - heat_loss: 3.7345\n",
      "Epoch 343/10000\n",
      "100/100 [==============================] - 0s 401us/step - loss: 4.2329 - xent_loss: 0.4984 - heat_loss: 3.7345\n",
      "Epoch 344/10000\n",
      "100/100 [==============================] - 0s 310us/step - loss: 4.2329 - xent_loss: 0.4984 - heat_loss: 3.7345\n",
      "Epoch 345/10000\n",
      "100/100 [==============================] - 0s 351us/step - loss: 4.2329 - xent_loss: 0.4984 - heat_loss: 3.7345\n",
      "Epoch 346/10000\n",
      "100/100 [==============================] - 0s 301us/step - loss: 4.2329 - xent_loss: 0.4984 - heat_loss: 3.7345\n",
      "Epoch 347/10000\n",
      "100/100 [==============================] - 0s 351us/step - loss: 4.2329 - xent_loss: 0.4984 - heat_loss: 3.7345\n",
      "Epoch 348/10000\n",
      "100/100 [==============================] - 0s 331us/step - loss: 4.2329 - xent_loss: 0.4984 - heat_loss: 3.7345\n",
      "Epoch 349/10000\n",
      "100/100 [==============================] - 0s 301us/step - loss: 4.2329 - xent_loss: 0.4984 - heat_loss: 3.7345\n",
      "Epoch 350/10000\n",
      "100/100 [==============================] - 0s 341us/step - loss: 4.2328 - xent_loss: 0.4984 - heat_loss: 3.7345\n",
      "Epoch 351/10000\n",
      "100/100 [==============================] - 0s 311us/step - loss: 4.2328 - xent_loss: 0.4984 - heat_loss: 3.7345\n",
      "Epoch 352/10000\n",
      "100/100 [==============================] - 0s 381us/step - loss: 4.2328 - xent_loss: 0.4984 - heat_loss: 3.7345\n",
      "Epoch 353/10000\n",
      "100/100 [==============================] - 0s 301us/step - loss: 4.2328 - xent_loss: 0.4984 - heat_loss: 3.7345\n",
      "Epoch 354/10000\n",
      "100/100 [==============================] - 0s 371us/step - loss: 4.2328 - xent_loss: 0.4984 - heat_loss: 3.7345\n",
      "Epoch 355/10000\n",
      "100/100 [==============================] - 0s 361us/step - loss: 4.2328 - xent_loss: 0.4984 - heat_loss: 3.7345\n",
      "Epoch 356/10000\n",
      "100/100 [==============================] - 0s 301us/step - loss: 4.2328 - xent_loss: 0.4983 - heat_loss: 3.7345\n",
      "Epoch 357/10000\n",
      "100/100 [==============================] - 0s 331us/step - loss: 4.2328 - xent_loss: 0.4983 - heat_loss: 3.7345\n",
      "Epoch 358/10000\n",
      "100/100 [==============================] - 0s 300us/step - loss: 4.2328 - xent_loss: 0.4983 - heat_loss: 3.7345\n",
      "Epoch 359/10000\n",
      "100/100 [==============================] - 0s 321us/step - loss: 4.2328 - xent_loss: 0.4983 - heat_loss: 3.7345\n",
      "Epoch 360/10000\n",
      "100/100 [==============================] - 0s 290us/step - loss: 4.2328 - xent_loss: 0.4983 - heat_loss: 3.7345\n",
      "Epoch 361/10000\n",
      "100/100 [==============================] - 0s 311us/step - loss: 4.2328 - xent_loss: 0.4983 - heat_loss: 3.7345\n",
      "Epoch 362/10000\n",
      "100/100 [==============================] - 0s 351us/step - loss: 4.2328 - xent_loss: 0.4983 - heat_loss: 3.7345\n",
      "Epoch 363/10000\n",
      "100/100 [==============================] - 0s 321us/step - loss: 4.2328 - xent_loss: 0.4983 - heat_loss: 3.7345\n",
      "Epoch 364/10000\n",
      "100/100 [==============================] - 0s 381us/step - loss: 4.2328 - xent_loss: 0.4983 - heat_loss: 3.7345\n",
      "Epoch 365/10000\n",
      "100/100 [==============================] - 0s 301us/step - loss: 4.2328 - xent_loss: 0.4983 - heat_loss: 3.7345\n",
      "Epoch 366/10000\n",
      "100/100 [==============================] - 0s 331us/step - loss: 4.2328 - xent_loss: 0.4983 - heat_loss: 3.7345\n",
      "Epoch 367/10000\n",
      "100/100 [==============================] - 0s 311us/step - loss: 4.2328 - xent_loss: 0.4983 - heat_loss: 3.7345\n",
      "Epoch 368/10000\n",
      "100/100 [==============================] - 0s 311us/step - loss: 4.2328 - xent_loss: 0.4983 - heat_loss: 3.7345\n",
      "Epoch 369/10000\n",
      "100/100 [==============================] - 0s 331us/step - loss: 4.2328 - xent_loss: 0.4983 - heat_loss: 3.7345\n",
      "Epoch 370/10000\n",
      "100/100 [==============================] - 0s 321us/step - loss: 4.2328 - xent_loss: 0.4983 - heat_loss: 3.7345\n",
      "Epoch 371/10000\n",
      "100/100 [==============================] - 0s 361us/step - loss: 4.2328 - xent_loss: 0.4983 - heat_loss: 3.7345\n",
      "Epoch 372/10000\n",
      "100/100 [==============================] - 0s 311us/step - loss: 4.2328 - xent_loss: 0.4983 - heat_loss: 3.7345\n",
      "Epoch 373/10000\n",
      "100/100 [==============================] - 0s 311us/step - loss: 4.2327 - xent_loss: 0.4983 - heat_loss: 3.7345\n",
      "Epoch 374/10000\n",
      "100/100 [==============================] - 0s 411us/step - loss: 4.2327 - xent_loss: 0.4983 - heat_loss: 3.7345\n",
      "Epoch 375/10000\n",
      "100/100 [==============================] - 0s 311us/step - loss: 4.2327 - xent_loss: 0.4983 - heat_loss: 3.7345\n",
      "Epoch 376/10000\n",
      "100/100 [==============================] - 0s 311us/step - loss: 4.2327 - xent_loss: 0.4983 - heat_loss: 3.7345\n",
      "Epoch 377/10000\n",
      "100/100 [==============================] - 0s 321us/step - loss: 4.2327 - xent_loss: 0.4983 - heat_loss: 3.7345\n",
      "Epoch 378/10000\n",
      "100/100 [==============================] - 0s 301us/step - loss: 4.2327 - xent_loss: 0.4982 - heat_loss: 3.7345\n",
      "Epoch 379/10000\n",
      "100/100 [==============================] - 0s 301us/step - loss: 4.2327 - xent_loss: 0.4982 - heat_loss: 3.7345\n",
      "Epoch 380/10000\n",
      "100/100 [==============================] - 0s 431us/step - loss: 4.2327 - xent_loss: 0.4982 - heat_loss: 3.7345\n",
      "Epoch 381/10000\n",
      "100/100 [==============================] - 0s 381us/step - loss: 4.2327 - xent_loss: 0.4982 - heat_loss: 3.7345\n",
      "Epoch 382/10000\n",
      "100/100 [==============================] - 0s 331us/step - loss: 4.2327 - xent_loss: 0.4982 - heat_loss: 3.7345\n",
      "Epoch 383/10000\n",
      "100/100 [==============================] - 0s 431us/step - loss: 4.2327 - xent_loss: 0.4982 - heat_loss: 3.7345\n",
      "Epoch 384/10000\n",
      "100/100 [==============================] - 0s 311us/step - loss: 4.2327 - xent_loss: 0.4982 - heat_loss: 3.7345\n",
      "Epoch 385/10000\n",
      "100/100 [==============================] - 0s 391us/step - loss: 4.2327 - xent_loss: 0.4982 - heat_loss: 3.7345\n",
      "Epoch 386/10000\n",
      "100/100 [==============================] - 0s 301us/step - loss: 4.2327 - xent_loss: 0.4982 - heat_loss: 3.7345\n",
      "Epoch 387/10000\n",
      "100/100 [==============================] - 0s 321us/step - loss: 4.2327 - xent_loss: 0.4982 - heat_loss: 3.7345\n",
      "Epoch 388/10000\n",
      "100/100 [==============================] - 0s 321us/step - loss: 4.2327 - xent_loss: 0.4982 - heat_loss: 3.7345\n",
      "Epoch 389/10000\n",
      "100/100 [==============================] - 0s 311us/step - loss: 4.2327 - xent_loss: 0.4982 - heat_loss: 3.7345\n",
      "Epoch 390/10000\n",
      "100/100 [==============================] - 0s 381us/step - loss: 4.2327 - xent_loss: 0.4982 - heat_loss: 3.7345\n",
      "Epoch 391/10000\n",
      "100/100 [==============================] - 0s 311us/step - loss: 4.2327 - xent_loss: 0.4982 - heat_loss: 3.7345\n",
      "Epoch 392/10000\n",
      "100/100 [==============================] - 0s 311us/step - loss: 4.2327 - xent_loss: 0.4982 - heat_loss: 3.7345\n",
      "Epoch 393/10000\n",
      "100/100 [==============================] - 0s 331us/step - loss: 4.2327 - xent_loss: 0.4982 - heat_loss: 3.7345\n",
      "Epoch 394/10000\n",
      "100/100 [==============================] - 0s 301us/step - loss: 4.2327 - xent_loss: 0.4982 - heat_loss: 3.7345\n",
      "Epoch 395/10000\n",
      "100/100 [==============================] - 0s 311us/step - loss: 4.2326 - xent_loss: 0.4982 - heat_loss: 3.7345\n",
      "Epoch 396/10000\n",
      "100/100 [==============================] - 0s 311us/step - loss: 4.2326 - xent_loss: 0.4982 - heat_loss: 3.7345\n",
      "Epoch 397/10000\n",
      "100/100 [==============================] - 0s 291us/step - loss: 4.2326 - xent_loss: 0.4982 - heat_loss: 3.7345\n",
      "Epoch 398/10000\n",
      "100/100 [==============================] - 0s 331us/step - loss: 4.2326 - xent_loss: 0.4982 - heat_loss: 3.7345\n",
      "Epoch 399/10000\n",
      "100/100 [==============================] - 0s 301us/step - loss: 4.2326 - xent_loss: 0.4982 - heat_loss: 3.7345\n",
      "Epoch 400/10000\n",
      "100/100 [==============================] - 0s 310us/step - loss: 4.2326 - xent_loss: 0.4981 - heat_loss: 3.7345\n",
      "Epoch 401/10000\n",
      "100/100 [==============================] - 0s 361us/step - loss: 4.2326 - xent_loss: 0.4981 - heat_loss: 3.7345\n",
      "Epoch 402/10000\n",
      "100/100 [==============================] - 0s 321us/step - loss: 4.2326 - xent_loss: 0.4981 - heat_loss: 3.7345\n",
      "Epoch 403/10000\n",
      "100/100 [==============================] - 0s 300us/step - loss: 4.2326 - xent_loss: 0.4981 - heat_loss: 3.7345\n",
      "Epoch 404/10000\n",
      "100/100 [==============================] - 0s 371us/step - loss: 4.2326 - xent_loss: 0.4981 - heat_loss: 3.7345\n",
      "Epoch 405/10000\n",
      "100/100 [==============================] - 0s 331us/step - loss: 4.2326 - xent_loss: 0.4981 - heat_loss: 3.7345\n",
      "Epoch 406/10000\n",
      "100/100 [==============================] - 0s 311us/step - loss: 4.2326 - xent_loss: 0.4981 - heat_loss: 3.7345\n",
      "Epoch 407/10000\n",
      "100/100 [==============================] - 0s 330us/step - loss: 4.2326 - xent_loss: 0.4981 - heat_loss: 3.7345\n",
      "Epoch 408/10000\n",
      "100/100 [==============================] - 0s 321us/step - loss: 4.2326 - xent_loss: 0.4981 - heat_loss: 3.7345\n",
      "Epoch 409/10000\n",
      "100/100 [==============================] - 0s 311us/step - loss: 4.2326 - xent_loss: 0.4981 - heat_loss: 3.7345\n",
      "Epoch 410/10000\n",
      "100/100 [==============================] - 0s 291us/step - loss: 4.2326 - xent_loss: 0.4981 - heat_loss: 3.7345\n",
      "Epoch 411/10000\n",
      "100/100 [==============================] - 0s 301us/step - loss: 4.2326 - xent_loss: 0.4981 - heat_loss: 3.7345\n",
      "Epoch 412/10000\n",
      "100/100 [==============================] - 0s 321us/step - loss: 4.2326 - xent_loss: 0.4981 - heat_loss: 3.7345\n",
      "Epoch 413/10000\n",
      "100/100 [==============================] - 0s 311us/step - loss: 4.2326 - xent_loss: 0.4981 - heat_loss: 3.7345\n",
      "Epoch 414/10000\n",
      "100/100 [==============================] - 0s 321us/step - loss: 4.2326 - xent_loss: 0.4981 - heat_loss: 3.7345\n",
      "Epoch 415/10000\n",
      "100/100 [==============================] - 0s 290us/step - loss: 4.2326 - xent_loss: 0.4981 - heat_loss: 3.7345\n",
      "Epoch 416/10000\n",
      "100/100 [==============================] - 0s 301us/step - loss: 4.2326 - xent_loss: 0.4981 - heat_loss: 3.7345\n",
      "Epoch 417/10000\n",
      "100/100 [==============================] - 0s 341us/step - loss: 4.2325 - xent_loss: 0.4981 - heat_loss: 3.7345\n",
      "Epoch 418/10000\n",
      "100/100 [==============================] - 0s 311us/step - loss: 4.2325 - xent_loss: 0.4981 - heat_loss: 3.7345\n",
      "Epoch 419/10000\n",
      "100/100 [==============================] - 0s 311us/step - loss: 4.2325 - xent_loss: 0.4981 - heat_loss: 3.7345\n",
      "Epoch 420/10000\n",
      "100/100 [==============================] - 0s 341us/step - loss: 4.2325 - xent_loss: 0.4981 - heat_loss: 3.7345\n",
      "Epoch 421/10000\n",
      "100/100 [==============================] - 0s 301us/step - loss: 4.2325 - xent_loss: 0.4981 - heat_loss: 3.7345\n",
      "Epoch 422/10000\n",
      "100/100 [==============================] - 0s 301us/step - loss: 4.2325 - xent_loss: 0.4980 - heat_loss: 3.7345\n",
      "Epoch 423/10000\n",
      "100/100 [==============================] - 0s 351us/step - loss: 4.2325 - xent_loss: 0.4980 - heat_loss: 3.7345\n",
      "Epoch 424/10000\n",
      "100/100 [==============================] - 0s 391us/step - loss: 4.2325 - xent_loss: 0.4980 - heat_loss: 3.7345\n",
      "Epoch 425/10000\n",
      "100/100 [==============================] - 0s 311us/step - loss: 4.2325 - xent_loss: 0.4980 - heat_loss: 3.7345\n",
      "Epoch 426/10000\n",
      "100/100 [==============================] - 0s 311us/step - loss: 4.2325 - xent_loss: 0.4980 - heat_loss: 3.7345\n",
      "Epoch 427/10000\n",
      "100/100 [==============================] - 0s 371us/step - loss: 4.2325 - xent_loss: 0.4980 - heat_loss: 3.7345\n",
      "Epoch 428/10000\n",
      "100/100 [==============================] - 0s 321us/step - loss: 4.2325 - xent_loss: 0.4980 - heat_loss: 3.7345\n",
      "Epoch 429/10000\n",
      "100/100 [==============================] - 0s 321us/step - loss: 4.2325 - xent_loss: 0.4980 - heat_loss: 3.7345\n",
      "Epoch 430/10000\n",
      "100/100 [==============================] - 0s 351us/step - loss: 4.2325 - xent_loss: 0.4980 - heat_loss: 3.7345\n",
      "Epoch 431/10000\n",
      "100/100 [==============================] - 0s 311us/step - loss: 4.2325 - xent_loss: 0.4980 - heat_loss: 3.7345\n",
      "Epoch 432/10000\n",
      "100/100 [==============================] - 0s 301us/step - loss: 4.2325 - xent_loss: 0.4980 - heat_loss: 3.7345\n",
      "Epoch 433/10000\n",
      "100/100 [==============================] - 0s 381us/step - loss: 4.2325 - xent_loss: 0.4980 - heat_loss: 3.7345\n",
      "Epoch 434/10000\n",
      "100/100 [==============================] - 0s 321us/step - loss: 4.2325 - xent_loss: 0.4980 - heat_loss: 3.7345\n",
      "Epoch 435/10000\n",
      "100/100 [==============================] - 0s 321us/step - loss: 4.2325 - xent_loss: 0.4980 - heat_loss: 3.7345\n",
      "Epoch 436/10000\n",
      "100/100 [==============================] - 0s 722us/step - loss: 4.2325 - xent_loss: 0.4980 - heat_loss: 3.7345\n",
      "Epoch 437/10000\n",
      "100/100 [==============================] - 0s 321us/step - loss: 4.2325 - xent_loss: 0.4980 - heat_loss: 3.7345\n",
      "Epoch 438/10000\n",
      "100/100 [==============================] - 0s 311us/step - loss: 4.2325 - xent_loss: 0.4980 - heat_loss: 3.7345\n",
      "Epoch 439/10000\n",
      "100/100 [==============================] - 0s 431us/step - loss: 4.2324 - xent_loss: 0.4980 - heat_loss: 3.7345\n",
      "Epoch 440/10000\n",
      "100/100 [==============================] - 0s 371us/step - loss: 4.2324 - xent_loss: 0.4980 - heat_loss: 3.7345\n",
      "Epoch 441/10000\n",
      "100/100 [==============================] - 0s 351us/step - loss: 4.2324 - xent_loss: 0.4980 - heat_loss: 3.7345\n",
      "Epoch 442/10000\n",
      "100/100 [==============================] - 0s 501us/step - loss: 4.2324 - xent_loss: 0.4980 - heat_loss: 3.7345\n",
      "Epoch 443/10000\n",
      "100/100 [==============================] - 0s 381us/step - loss: 4.2324 - xent_loss: 0.4979 - heat_loss: 3.7345\n",
      "Epoch 444/10000\n",
      "100/100 [==============================] - 0s 441us/step - loss: 4.2324 - xent_loss: 0.4979 - heat_loss: 3.7345\n",
      "Epoch 445/10000\n",
      "100/100 [==============================] - 0s 451us/step - loss: 4.2324 - xent_loss: 0.4979 - heat_loss: 3.7345\n",
      "Epoch 446/10000\n",
      "100/100 [==============================] - 0s 521us/step - loss: 4.2324 - xent_loss: 0.4979 - heat_loss: 3.7345\n",
      "Epoch 447/10000\n",
      "100/100 [==============================] - 0s 441us/step - loss: 4.2324 - xent_loss: 0.4979 - heat_loss: 3.7345\n",
      "Epoch 448/10000\n",
      "100/100 [==============================] - 0s 471us/step - loss: 4.2324 - xent_loss: 0.4979 - heat_loss: 3.7345\n",
      "Epoch 449/10000\n",
      "100/100 [==============================] - 0s 491us/step - loss: 4.2324 - xent_loss: 0.4979 - heat_loss: 3.7345\n",
      "Epoch 450/10000\n",
      "100/100 [==============================] - 0s 451us/step - loss: 4.2324 - xent_loss: 0.4979 - heat_loss: 3.7345\n",
      "Epoch 451/10000\n",
      "100/100 [==============================] - 0s 499us/step - loss: 4.2324 - xent_loss: 0.4979 - heat_loss: 3.7345\n",
      "Epoch 452/10000\n",
      "100/100 [==============================] - 0s 361us/step - loss: 4.2324 - xent_loss: 0.4979 - heat_loss: 3.7345\n",
      "Epoch 453/10000\n",
      "100/100 [==============================] - 0s 401us/step - loss: 4.2324 - xent_loss: 0.4979 - heat_loss: 3.7345\n",
      "Epoch 454/10000\n",
      "100/100 [==============================] - 0s 461us/step - loss: 4.2324 - xent_loss: 0.4979 - heat_loss: 3.7345\n",
      "Epoch 455/10000\n",
      "100/100 [==============================] - 0s 481us/step - loss: 4.2324 - xent_loss: 0.4979 - heat_loss: 3.7345\n",
      "Epoch 456/10000\n",
      "100/100 [==============================] - 0s 371us/step - loss: 4.2324 - xent_loss: 0.4979 - heat_loss: 3.7345\n",
      "Epoch 457/10000\n",
      "100/100 [==============================] - 0s 381us/step - loss: 4.2324 - xent_loss: 0.4979 - heat_loss: 3.7345\n",
      "Epoch 458/10000\n",
      "100/100 [==============================] - 0s 331us/step - loss: 4.2324 - xent_loss: 0.4979 - heat_loss: 3.7345\n",
      "Epoch 459/10000\n",
      "100/100 [==============================] - 0s 461us/step - loss: 4.2323 - xent_loss: 0.4979 - heat_loss: 3.7345\n",
      "Epoch 460/10000\n",
      "100/100 [==============================] - 0s 852us/step - loss: 4.2323 - xent_loss: 0.4979 - heat_loss: 3.7345\n",
      "Epoch 461/10000\n",
      "100/100 [==============================] - 0s 892us/step - loss: 4.2323 - xent_loss: 0.4979 - heat_loss: 3.7345\n",
      "Epoch 462/10000\n",
      "100/100 [==============================] - 0s 792us/step - loss: 4.2323 - xent_loss: 0.4979 - heat_loss: 3.7345\n",
      "Epoch 463/10000\n",
      "100/100 [==============================] - 0s 411us/step - loss: 4.2323 - xent_loss: 0.4979 - heat_loss: 3.7345\n",
      "Epoch 464/10000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.2323 - xent_loss: 0.4978 - heat_loss: 3.7345\n",
      "Epoch 465/10000\n",
      "100/100 [==============================] - 0s 351us/step - loss: 4.2323 - xent_loss: 0.4978 - heat_loss: 3.7345\n",
      "Epoch 466/10000\n",
      "100/100 [==============================] - 0s 351us/step - loss: 4.2323 - xent_loss: 0.4978 - heat_loss: 3.7345\n",
      "Epoch 467/10000\n",
      "100/100 [==============================] - 0s 599us/step - loss: 4.2323 - xent_loss: 0.4978 - heat_loss: 3.7345\n",
      "Epoch 468/10000\n",
      "100/100 [==============================] - 0s 671us/step - loss: 4.2323 - xent_loss: 0.4978 - heat_loss: 3.7345\n",
      "Epoch 469/10000\n",
      "100/100 [==============================] - 0s 441us/step - loss: 4.2323 - xent_loss: 0.4978 - heat_loss: 3.7345\n",
      "Epoch 470/10000\n",
      "100/100 [==============================] - 0s 441us/step - loss: 4.2323 - xent_loss: 0.4978 - heat_loss: 3.7345\n",
      "Epoch 471/10000\n",
      "100/100 [==============================] - 0s 983us/step - loss: 4.2323 - xent_loss: 0.4978 - heat_loss: 3.7345\n",
      "Epoch 472/10000\n",
      "100/100 [==============================] - 0s 842us/step - loss: 4.2323 - xent_loss: 0.4978 - heat_loss: 3.7345\n",
      "Epoch 473/10000\n",
      "100/100 [==============================] - 0s 511us/step - loss: 4.2323 - xent_loss: 0.4978 - heat_loss: 3.7345\n",
      "Epoch 474/10000\n",
      "100/100 [==============================] - 0s 451us/step - loss: 4.2323 - xent_loss: 0.4978 - heat_loss: 3.7345\n",
      "Epoch 475/10000\n",
      "100/100 [==============================] - 0s 571us/step - loss: 4.2323 - xent_loss: 0.4978 - heat_loss: 3.7345\n",
      "Epoch 476/10000\n",
      "100/100 [==============================] - 0s 451us/step - loss: 4.2323 - xent_loss: 0.4978 - heat_loss: 3.7345\n",
      "Epoch 477/10000\n",
      "100/100 [==============================] - 0s 551us/step - loss: 4.2323 - xent_loss: 0.4978 - heat_loss: 3.7345\n",
      "Epoch 478/10000\n",
      "100/100 [==============================] - 0s 461us/step - loss: 4.2323 - xent_loss: 0.4978 - heat_loss: 3.7345\n",
      "Epoch 479/10000\n",
      "100/100 [==============================] - 0s 431us/step - loss: 4.2323 - xent_loss: 0.4978 - heat_loss: 3.7345\n",
      "Epoch 480/10000\n",
      "100/100 [==============================] - 0s 351us/step - loss: 4.2322 - xent_loss: 0.4978 - heat_loss: 3.7345\n",
      "Epoch 481/10000\n",
      "100/100 [==============================] - 0s 341us/step - loss: 4.2322 - xent_loss: 0.4978 - heat_loss: 3.7345\n",
      "Epoch 482/10000\n",
      "100/100 [==============================] - 0s 652us/step - loss: 4.2322 - xent_loss: 0.4978 - heat_loss: 3.7345\n",
      "Epoch 483/10000\n",
      "100/100 [==============================] - 0s 381us/step - loss: 4.2322 - xent_loss: 0.4978 - heat_loss: 3.7345\n",
      "Epoch 484/10000\n",
      "100/100 [==============================] - 0s 361us/step - loss: 4.2322 - xent_loss: 0.4978 - heat_loss: 3.7345\n",
      "Epoch 485/10000\n",
      "100/100 [==============================] - 0s 882us/step - loss: 4.2322 - xent_loss: 0.4977 - heat_loss: 3.7345\n",
      "Epoch 486/10000\n",
      "100/100 [==============================] - 0s 351us/step - loss: 4.2322 - xent_loss: 0.4977 - heat_loss: 3.7345\n",
      "Epoch 487/10000\n",
      "100/100 [==============================] - 0s 832us/step - loss: 4.2322 - xent_loss: 0.4977 - heat_loss: 3.7345\n",
      "Epoch 488/10000\n",
      "100/100 [==============================] - 0s 782us/step - loss: 4.2322 - xent_loss: 0.4977 - heat_loss: 3.7345\n",
      "Epoch 489/10000\n",
      "100/100 [==============================] - 0s 521us/step - loss: 4.2322 - xent_loss: 0.4977 - heat_loss: 3.7345\n",
      "Epoch 490/10000\n",
      "100/100 [==============================] - 0s 572us/step - loss: 4.2322 - xent_loss: 0.4977 - heat_loss: 3.7345\n",
      "Epoch 491/10000\n",
      "100/100 [==============================] - 0s 481us/step - loss: 4.2322 - xent_loss: 0.4977 - heat_loss: 3.7345\n",
      "Epoch 492/10000\n",
      "100/100 [==============================] - 0s 551us/step - loss: 4.2322 - xent_loss: 0.4977 - heat_loss: 3.7345\n",
      "Epoch 493/10000\n",
      "100/100 [==============================] - 0s 381us/step - loss: 4.2322 - xent_loss: 0.4977 - heat_loss: 3.7345\n",
      "Epoch 494/10000\n",
      "100/100 [==============================] - 0s 632us/step - loss: 4.2322 - xent_loss: 0.4977 - heat_loss: 3.7345\n",
      "Epoch 495/10000\n",
      "100/100 [==============================] - 0s 451us/step - loss: 4.2322 - xent_loss: 0.4977 - heat_loss: 3.7345\n",
      "Epoch 496/10000\n",
      "100/100 [==============================] - 0s 391us/step - loss: 4.2322 - xent_loss: 0.4977 - heat_loss: 3.7345\n",
      "Epoch 497/10000\n",
      "100/100 [==============================] - 0s 752us/step - loss: 4.2322 - xent_loss: 0.4977 - heat_loss: 3.7345\n",
      "Epoch 498/10000\n",
      "100/100 [==============================] - 0s 351us/step - loss: 4.2322 - xent_loss: 0.4977 - heat_loss: 3.7345\n",
      "Epoch 499/10000\n",
      "100/100 [==============================] - 0s 892us/step - loss: 4.2322 - xent_loss: 0.4977 - heat_loss: 3.7345\n",
      "Epoch 500/10000\n",
      "100/100 [==============================] - 0s 742us/step - loss: 4.2321 - xent_loss: 0.4977 - heat_loss: 3.7345\n",
      "Epoch 501/10000\n",
      "100/100 [==============================] - 0s 331us/step - loss: 4.2321 - xent_loss: 0.4977 - heat_loss: 3.7345\n",
      "Epoch 502/10000\n",
      "100/100 [==============================] - 0s 301us/step - loss: 4.2321 - xent_loss: 0.4977 - heat_loss: 3.7345\n",
      "Epoch 503/10000\n",
      "100/100 [==============================] - 0s 391us/step - loss: 4.2321 - xent_loss: 0.4977 - heat_loss: 3.7345\n",
      "Epoch 504/10000\n",
      "100/100 [==============================] - 0s 321us/step - loss: 4.2321 - xent_loss: 0.4977 - heat_loss: 3.7345\n",
      "Epoch 505/10000\n",
      "100/100 [==============================] - 0s 983us/step - loss: 4.2321 - xent_loss: 0.4976 - heat_loss: 3.7345\n",
      "Epoch 506/10000\n",
      "100/100 [==============================] - 0s 802us/step - loss: 4.2321 - xent_loss: 0.4976 - heat_loss: 3.7345\n",
      "Epoch 507/10000\n",
      "100/100 [==============================] - 0s 902us/step - loss: 4.2321 - xent_loss: 0.4976 - heat_loss: 3.7345\n",
      "Epoch 508/10000\n",
      "100/100 [==============================] - 0s 902us/step - loss: 4.2321 - xent_loss: 0.4976 - heat_loss: 3.7345\n",
      "Epoch 509/10000\n",
      "100/100 [==============================] - 0s 411us/step - loss: 4.2321 - xent_loss: 0.4976 - heat_loss: 3.7345\n",
      "Epoch 510/10000\n",
      "100/100 [==============================] - 0s 391us/step - loss: 4.2321 - xent_loss: 0.4976 - heat_loss: 3.7345\n",
      "Epoch 511/10000\n",
      "100/100 [==============================] - 0s 461us/step - loss: 4.2321 - xent_loss: 0.4976 - heat_loss: 3.7345\n",
      "Epoch 512/10000\n",
      "100/100 [==============================] - 0s 421us/step - loss: 4.2321 - xent_loss: 0.4976 - heat_loss: 3.7345\n",
      "Epoch 513/10000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.2321 - xent_loss: 0.4976 - heat_loss: 3.7345\n",
      "Epoch 514/10000\n",
      "100/100 [==============================] - 0s 421us/step - loss: 4.2321 - xent_loss: 0.4976 - heat_loss: 3.7345\n",
      "Epoch 515/10000\n",
      "100/100 [==============================] - 0s 752us/step - loss: 4.2321 - xent_loss: 0.4976 - heat_loss: 3.7345\n",
      "Epoch 516/10000\n",
      "100/100 [==============================] - 0s 572us/step - loss: 4.2321 - xent_loss: 0.4976 - heat_loss: 3.7345\n",
      "Epoch 517/10000\n",
      "100/100 [==============================] - 0s 792us/step - loss: 4.2321 - xent_loss: 0.4976 - heat_loss: 3.7345\n",
      "Epoch 518/10000\n",
      "100/100 [==============================] - 0s 341us/step - loss: 4.2321 - xent_loss: 0.4976 - heat_loss: 3.7345\n",
      "Epoch 519/10000\n",
      "100/100 [==============================] - 0s 882us/step - loss: 4.2321 - xent_loss: 0.4976 - heat_loss: 3.7345\n",
      "Epoch 520/10000\n",
      "100/100 [==============================] - 0s 401us/step - loss: 4.2320 - xent_loss: 0.4976 - heat_loss: 3.7345\n",
      "Epoch 521/10000\n",
      "100/100 [==============================] - 0s 431us/step - loss: 4.2320 - xent_loss: 0.4976 - heat_loss: 3.7345\n",
      "Epoch 522/10000\n",
      "100/100 [==============================] - 0s 371us/step - loss: 4.2320 - xent_loss: 0.4976 - heat_loss: 3.7345\n",
      "Epoch 523/10000\n",
      "100/100 [==============================] - 0s 421us/step - loss: 4.2320 - xent_loss: 0.4976 - heat_loss: 3.7345\n",
      "Epoch 524/10000\n",
      "100/100 [==============================] - 0s 331us/step - loss: 4.2320 - xent_loss: 0.4976 - heat_loss: 3.7345\n",
      "Epoch 525/10000\n",
      "100/100 [==============================] - 0s 471us/step - loss: 4.2320 - xent_loss: 0.4975 - heat_loss: 3.7345\n",
      "Epoch 526/10000\n",
      "100/100 [==============================] - 0s 511us/step - loss: 4.2320 - xent_loss: 0.4975 - heat_loss: 3.7345\n",
      "Epoch 527/10000\n",
      "100/100 [==============================] - 0s 301us/step - loss: 4.2320 - xent_loss: 0.4975 - heat_loss: 3.7345\n",
      "Epoch 528/10000\n",
      "100/100 [==============================] - 0s 309us/step - loss: 4.2320 - xent_loss: 0.4975 - heat_loss: 3.7345\n",
      "Epoch 529/10000\n",
      "100/100 [==============================] - 0s 441us/step - loss: 4.2320 - xent_loss: 0.4975 - heat_loss: 3.7345\n",
      "Epoch 530/10000\n",
      "100/100 [==============================] - 0s 461us/step - loss: 4.2320 - xent_loss: 0.4975 - heat_loss: 3.7345\n",
      "Epoch 531/10000\n",
      "100/100 [==============================] - 0s 351us/step - loss: 4.2320 - xent_loss: 0.4975 - heat_loss: 3.7345\n",
      "Epoch 532/10000\n",
      "100/100 [==============================] - 0s 421us/step - loss: 4.2320 - xent_loss: 0.4975 - heat_loss: 3.7345\n",
      "Epoch 533/10000\n",
      "100/100 [==============================] - 0s 361us/step - loss: 4.2320 - xent_loss: 0.4975 - heat_loss: 3.7345\n",
      "Epoch 534/10000\n",
      "100/100 [==============================] - 0s 351us/step - loss: 4.2320 - xent_loss: 0.4975 - heat_loss: 3.7345\n",
      "Epoch 535/10000\n",
      "100/100 [==============================] - 0s 421us/step - loss: 4.2320 - xent_loss: 0.4975 - heat_loss: 3.7345\n",
      "Epoch 536/10000\n",
      "100/100 [==============================] - 0s 361us/step - loss: 4.2320 - xent_loss: 0.4975 - heat_loss: 3.7345\n",
      "Epoch 537/10000\n",
      "100/100 [==============================] - 0s 381us/step - loss: 4.2320 - xent_loss: 0.4975 - heat_loss: 3.7345\n",
      "Epoch 538/10000\n",
      "100/100 [==============================] - 0s 441us/step - loss: 4.2320 - xent_loss: 0.4975 - heat_loss: 3.7345\n",
      "Epoch 539/10000\n",
      "100/100 [==============================] - 0s 391us/step - loss: 4.2320 - xent_loss: 0.4975 - heat_loss: 3.7345\n",
      "Epoch 540/10000\n",
      "100/100 [==============================] - 0s 331us/step - loss: 4.2319 - xent_loss: 0.4975 - heat_loss: 3.7345\n",
      "Epoch 541/10000\n",
      "100/100 [==============================] - 0s 391us/step - loss: 4.2319 - xent_loss: 0.4975 - heat_loss: 3.7345\n",
      "Epoch 542/10000\n",
      "100/100 [==============================] - 0s 431us/step - loss: 4.2319 - xent_loss: 0.4975 - heat_loss: 3.7345\n",
      "Epoch 543/10000\n",
      "100/100 [==============================] - 0s 401us/step - loss: 4.2319 - xent_loss: 0.4975 - heat_loss: 3.7345\n",
      "Epoch 544/10000\n",
      "100/100 [==============================] - 0s 431us/step - loss: 4.2319 - xent_loss: 0.4975 - heat_loss: 3.7345\n",
      "Epoch 545/10000\n",
      "100/100 [==============================] - 0s 872us/step - loss: 4.2319 - xent_loss: 0.4974 - heat_loss: 3.7345\n",
      "Epoch 546/10000\n",
      "100/100 [==============================] - 0s 381us/step - loss: 4.2319 - xent_loss: 0.4974 - heat_loss: 3.7345\n",
      "Epoch 547/10000\n",
      "100/100 [==============================] - 0s 331us/step - loss: 4.2319 - xent_loss: 0.4974 - heat_loss: 3.7345\n",
      "Epoch 548/10000\n",
      "100/100 [==============================] - 0s 451us/step - loss: 4.2319 - xent_loss: 0.4974 - heat_loss: 3.7345\n",
      "Epoch 549/10000\n",
      "100/100 [==============================] - 0s 371us/step - loss: 4.2319 - xent_loss: 0.4974 - heat_loss: 3.7345\n",
      "Epoch 550/10000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.2319 - xent_loss: 0.4974 - heat_loss: 3.7345\n",
      "Epoch 551/10000\n",
      "100/100 [==============================] - 0s 562us/step - loss: 4.2319 - xent_loss: 0.4974 - heat_loss: 3.7345\n",
      "Epoch 552/10000\n",
      "100/100 [==============================] - 0s 431us/step - loss: 4.2319 - xent_loss: 0.4974 - heat_loss: 3.7345\n",
      "Epoch 553/10000\n",
      "100/100 [==============================] - 0s 361us/step - loss: 4.2319 - xent_loss: 0.4974 - heat_loss: 3.7345\n",
      "Epoch 554/10000\n",
      "100/100 [==============================] - 0s 321us/step - loss: 4.2319 - xent_loss: 0.4974 - heat_loss: 3.7345\n",
      "Epoch 555/10000\n",
      "100/100 [==============================] - 0s 391us/step - loss: 4.2319 - xent_loss: 0.4974 - heat_loss: 3.7345\n",
      "Epoch 556/10000\n",
      "100/100 [==============================] - 0s 411us/step - loss: 4.2319 - xent_loss: 0.4974 - heat_loss: 3.7345\n",
      "Epoch 557/10000\n",
      "100/100 [==============================] - 0s 381us/step - loss: 4.2319 - xent_loss: 0.4974 - heat_loss: 3.7345\n",
      "Epoch 558/10000\n",
      "100/100 [==============================] - 0s 381us/step - loss: 4.2319 - xent_loss: 0.4974 - heat_loss: 3.7345\n",
      "Epoch 559/10000\n",
      "100/100 [==============================] - 0s 351us/step - loss: 4.2318 - xent_loss: 0.4974 - heat_loss: 3.7345\n",
      "Epoch 560/10000\n",
      "100/100 [==============================] - 0s 351us/step - loss: 4.2318 - xent_loss: 0.4974 - heat_loss: 3.7345\n",
      "Epoch 561/10000\n",
      "100/100 [==============================] - 0s 341us/step - loss: 4.2318 - xent_loss: 0.4974 - heat_loss: 3.7345\n",
      "Epoch 562/10000\n",
      "100/100 [==============================] - 0s 361us/step - loss: 4.2318 - xent_loss: 0.4974 - heat_loss: 3.7345\n",
      "Epoch 563/10000\n",
      "100/100 [==============================] - 0s 341us/step - loss: 4.2318 - xent_loss: 0.4974 - heat_loss: 3.7345\n",
      "Epoch 564/10000\n",
      "100/100 [==============================] - 0s 435us/step - loss: 4.2318 - xent_loss: 0.4973 - heat_loss: 3.7345\n",
      "Epoch 565/10000\n",
      "100/100 [==============================] - 0s 400us/step - loss: 4.2318 - xent_loss: 0.4973 - heat_loss: 3.7345\n",
      "Epoch 566/10000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.2318 - xent_loss: 0.4973 - heat_loss: 3.7345\n",
      "Epoch 567/10000\n",
      "100/100 [==============================] - 0s 400us/step - loss: 4.2318 - xent_loss: 0.4973 - heat_loss: 3.7345\n",
      "Epoch 568/10000\n",
      "100/100 [==============================] - 0s 300us/step - loss: 4.2318 - xent_loss: 0.4973 - heat_loss: 3.7345\n",
      "Epoch 569/10000\n",
      "100/100 [==============================] - 0s 300us/step - loss: 4.2318 - xent_loss: 0.4973 - heat_loss: 3.7345\n",
      "Epoch 570/10000\n",
      "100/100 [==============================] - 0s 300us/step - loss: 4.2318 - xent_loss: 0.4973 - heat_loss: 3.7345\n",
      "Epoch 571/10000\n",
      "100/100 [==============================] - 0s 800us/step - loss: 4.2318 - xent_loss: 0.4973 - heat_loss: 3.7345\n",
      "Epoch 572/10000\n",
      "100/100 [==============================] - 0s 600us/step - loss: 4.2318 - xent_loss: 0.4973 - heat_loss: 3.7345\n",
      "Epoch 573/10000\n",
      "100/100 [==============================] - 0s 923us/step - loss: 4.2318 - xent_loss: 0.4973 - heat_loss: 3.7345\n",
      "Epoch 574/10000\n",
      "100/100 [==============================] - 0s 642us/step - loss: 4.2318 - xent_loss: 0.4973 - heat_loss: 3.7345\n",
      "Epoch 575/10000\n",
      "100/100 [==============================] - 0s 371us/step - loss: 4.2318 - xent_loss: 0.4973 - heat_loss: 3.7345\n",
      "Epoch 576/10000\n",
      "100/100 [==============================] - 0s 521us/step - loss: 4.2318 - xent_loss: 0.4973 - heat_loss: 3.7345\n",
      "Epoch 577/10000\n",
      "100/100 [==============================] - 0s 341us/step - loss: 4.2318 - xent_loss: 0.4973 - heat_loss: 3.7345\n",
      "Epoch 578/10000\n",
      "100/100 [==============================] - 0s 331us/step - loss: 4.2318 - xent_loss: 0.4973 - heat_loss: 3.7345\n",
      "Epoch 579/10000\n",
      "100/100 [==============================] - 0s 501us/step - loss: 4.2317 - xent_loss: 0.4973 - heat_loss: 3.7345\n",
      "Epoch 580/10000\n",
      "100/100 [==============================] - 0s 441us/step - loss: 4.2317 - xent_loss: 0.4973 - heat_loss: 3.7345\n",
      "Epoch 581/10000\n",
      "100/100 [==============================] - 0s 381us/step - loss: 4.2317 - xent_loss: 0.4973 - heat_loss: 3.7345\n",
      "Epoch 582/10000\n",
      "100/100 [==============================] - 0s 361us/step - loss: 4.2317 - xent_loss: 0.4973 - heat_loss: 3.7345\n",
      "Epoch 583/10000\n",
      "100/100 [==============================] - 0s 341us/step - loss: 4.2317 - xent_loss: 0.4972 - heat_loss: 3.7345\n",
      "Epoch 584/10000\n",
      "100/100 [==============================] - 0s 311us/step - loss: 4.2317 - xent_loss: 0.4972 - heat_loss: 3.7345\n",
      "Epoch 585/10000\n",
      "100/100 [==============================] - 0s 401us/step - loss: 4.2317 - xent_loss: 0.4972 - heat_loss: 3.7345\n",
      "Epoch 586/10000\n",
      "100/100 [==============================] - 0s 351us/step - loss: 4.2317 - xent_loss: 0.4972 - heat_loss: 3.7345\n",
      "Epoch 587/10000\n",
      "100/100 [==============================] - 0s 461us/step - loss: 4.2317 - xent_loss: 0.4972 - heat_loss: 3.7345\n",
      "Epoch 588/10000\n",
      "100/100 [==============================] - 0s 792us/step - loss: 4.2317 - xent_loss: 0.4972 - heat_loss: 3.7345\n",
      "Epoch 589/10000\n",
      "100/100 [==============================] - 0s 765us/step - loss: 4.2317 - xent_loss: 0.4972 - heat_loss: 3.7345\n",
      "Epoch 590/10000\n",
      "100/100 [==============================] - 0s 501us/step - loss: 4.2317 - xent_loss: 0.4972 - heat_loss: 3.7345\n",
      "Epoch 591/10000\n",
      "100/100 [==============================] - 0s 381us/step - loss: 4.2317 - xent_loss: 0.4972 - heat_loss: 3.7345\n",
      "Epoch 592/10000\n",
      "100/100 [==============================] - 0s 341us/step - loss: 4.2317 - xent_loss: 0.4972 - heat_loss: 3.7345\n",
      "Epoch 593/10000\n",
      "100/100 [==============================] - 0s 451us/step - loss: 4.2317 - xent_loss: 0.4972 - heat_loss: 3.7345\n",
      "Epoch 594/10000\n",
      "100/100 [==============================] - 0s 461us/step - loss: 4.2317 - xent_loss: 0.4972 - heat_loss: 3.7345\n",
      "Epoch 595/10000\n",
      "100/100 [==============================] - 0s 371us/step - loss: 4.2317 - xent_loss: 0.4972 - heat_loss: 3.7345\n",
      "Epoch 596/10000\n",
      "100/100 [==============================] - 0s 381us/step - loss: 4.2317 - xent_loss: 0.4972 - heat_loss: 3.7345\n",
      "Epoch 597/10000\n",
      "100/100 [==============================] - 0s 421us/step - loss: 4.2316 - xent_loss: 0.4972 - heat_loss: 3.7345\n",
      "Epoch 598/10000\n",
      "100/100 [==============================] - 0s 300us/step - loss: 4.2316 - xent_loss: 0.4972 - heat_loss: 3.7345\n",
      "Epoch 599/10000\n",
      "100/100 [==============================] - 0s 300us/step - loss: 4.2316 - xent_loss: 0.4972 - heat_loss: 3.7345\n",
      "Epoch 600/10000\n",
      "100/100 [==============================] - 0s 930us/step - loss: 4.2316 - xent_loss: 0.4972 - heat_loss: 3.7345\n",
      "Epoch 601/10000\n",
      "100/100 [==============================] - 0s 816us/step - loss: 4.2316 - xent_loss: 0.4972 - heat_loss: 3.7345\n",
      "Epoch 602/10000\n",
      "100/100 [==============================] - 0s 795us/step - loss: 4.2316 - xent_loss: 0.4971 - heat_loss: 3.7345\n",
      "Epoch 603/10000\n",
      "100/100 [==============================] - 0s 300us/step - loss: 4.2316 - xent_loss: 0.4971 - heat_loss: 3.7345\n",
      "Epoch 604/10000\n",
      "100/100 [==============================] - 0s 371us/step - loss: 4.2316 - xent_loss: 0.4971 - heat_loss: 3.7345\n",
      "Epoch 605/10000\n",
      "100/100 [==============================] - 0s 404us/step - loss: 4.2316 - xent_loss: 0.4971 - heat_loss: 3.7345\n",
      "Epoch 606/10000\n",
      "100/100 [==============================] - 0s 321us/step - loss: 4.2316 - xent_loss: 0.4971 - heat_loss: 3.7345\n",
      "Epoch 607/10000\n",
      "100/100 [==============================] - 0s 481us/step - loss: 4.2316 - xent_loss: 0.4971 - heat_loss: 3.7345\n",
      "Epoch 608/10000\n",
      "100/100 [==============================] - 0s 616us/step - loss: 4.2316 - xent_loss: 0.4971 - heat_loss: 3.7345\n",
      "Epoch 609/10000\n",
      "100/100 [==============================] - 0s 500us/step - loss: 4.2316 - xent_loss: 0.4971 - heat_loss: 3.7345\n",
      "Epoch 610/10000\n",
      "100/100 [==============================] - 0s 500us/step - loss: 4.2316 - xent_loss: 0.4971 - heat_loss: 3.7345\n",
      "Epoch 611/10000\n",
      "100/100 [==============================] - 0s 857us/step - loss: 4.2316 - xent_loss: 0.4971 - heat_loss: 3.7345\n",
      "Epoch 612/10000\n",
      "100/100 [==============================] - 0s 696us/step - loss: 4.2316 - xent_loss: 0.4971 - heat_loss: 3.7345\n",
      "Epoch 613/10000\n",
      "100/100 [==============================] - 0s 331us/step - loss: 4.2316 - xent_loss: 0.4971 - heat_loss: 3.7345\n",
      "Epoch 614/10000\n",
      "100/100 [==============================] - 0s 361us/step - loss: 4.2316 - xent_loss: 0.4971 - heat_loss: 3.7345\n",
      "Epoch 615/10000\n",
      "100/100 [==============================] - 0s 401us/step - loss: 4.2315 - xent_loss: 0.4971 - heat_loss: 3.7345\n",
      "Epoch 616/10000\n",
      "100/100 [==============================] - 0s 351us/step - loss: 4.2315 - xent_loss: 0.4971 - heat_loss: 3.7345\n",
      "Epoch 617/10000\n",
      "100/100 [==============================] - 0s 371us/step - loss: 4.2315 - xent_loss: 0.4971 - heat_loss: 3.7345\n",
      "Epoch 618/10000\n",
      "100/100 [==============================] - 0s 321us/step - loss: 4.2315 - xent_loss: 0.4971 - heat_loss: 3.7345\n",
      "Epoch 619/10000\n",
      "100/100 [==============================] - 0s 371us/step - loss: 4.2315 - xent_loss: 0.4971 - heat_loss: 3.7345\n",
      "Epoch 620/10000\n",
      "100/100 [==============================] - 0s 411us/step - loss: 4.2315 - xent_loss: 0.4970 - heat_loss: 3.7345\n",
      "Epoch 621/10000\n",
      "100/100 [==============================] - 0s 653us/step - loss: 4.2315 - xent_loss: 0.4970 - heat_loss: 3.7345\n",
      "Epoch 622/10000\n",
      "100/100 [==============================] - 0s 999us/step - loss: 4.2315 - xent_loss: 0.4970 - heat_loss: 3.7345\n",
      "Epoch 623/10000\n",
      "100/100 [==============================] - 0s 331us/step - loss: 4.2315 - xent_loss: 0.4970 - heat_loss: 3.7345\n",
      "Epoch 624/10000\n",
      "100/100 [==============================] - 0s 300us/step - loss: 4.2315 - xent_loss: 0.4970 - heat_loss: 3.7345\n",
      "Epoch 625/10000\n",
      "100/100 [==============================] - 0s 977us/step - loss: 4.2315 - xent_loss: 0.4970 - heat_loss: 3.7345\n",
      "Epoch 626/10000\n",
      "100/100 [==============================] - 0s 351us/step - loss: 4.2315 - xent_loss: 0.4970 - heat_loss: 3.7345\n",
      "Epoch 627/10000\n",
      "100/100 [==============================] - 0s 984us/step - loss: 4.2315 - xent_loss: 0.4970 - heat_loss: 3.7345\n",
      "Epoch 628/10000\n",
      "100/100 [==============================] - 0s 411us/step - loss: 4.2315 - xent_loss: 0.4970 - heat_loss: 3.7345\n",
      "Epoch 629/10000\n",
      "100/100 [==============================] - 0s 331us/step - loss: 4.2315 - xent_loss: 0.4970 - heat_loss: 3.7345\n",
      "Epoch 630/10000\n",
      "100/100 [==============================] - 0s 371us/step - loss: 4.2315 - xent_loss: 0.4970 - heat_loss: 3.7345\n",
      "Epoch 631/10000\n",
      "100/100 [==============================] - 0s 321us/step - loss: 4.2315 - xent_loss: 0.4970 - heat_loss: 3.7345\n",
      "Epoch 632/10000\n",
      "100/100 [==============================] - 0s 808us/step - loss: 4.2315 - xent_loss: 0.4970 - heat_loss: 3.7345\n",
      "Epoch 633/10000\n",
      "100/100 [==============================] - 0s 351us/step - loss: 4.2315 - xent_loss: 0.4970 - heat_loss: 3.7345\n",
      "Epoch 634/10000\n",
      "100/100 [==============================] - 0s 371us/step - loss: 4.2314 - xent_loss: 0.4970 - heat_loss: 3.7345\n",
      "Epoch 635/10000\n",
      "100/100 [==============================] - 0s 371us/step - loss: 4.2314 - xent_loss: 0.4970 - heat_loss: 3.7345\n",
      "Epoch 636/10000\n",
      "100/100 [==============================] - 0s 331us/step - loss: 4.2314 - xent_loss: 0.4970 - heat_loss: 3.7345\n",
      "Epoch 637/10000\n",
      "100/100 [==============================] - 0s 341us/step - loss: 4.2314 - xent_loss: 0.4970 - heat_loss: 3.7345\n",
      "Epoch 638/10000\n",
      "100/100 [==============================] - 0s 361us/step - loss: 4.2314 - xent_loss: 0.4970 - heat_loss: 3.7345\n",
      "Epoch 639/10000\n",
      "100/100 [==============================] - 0s 341us/step - loss: 4.2314 - xent_loss: 0.4969 - heat_loss: 3.7345\n",
      "Epoch 640/10000\n",
      "100/100 [==============================] - 0s 411us/step - loss: 4.2314 - xent_loss: 0.4969 - heat_loss: 3.7345\n",
      "Epoch 641/10000\n",
      "100/100 [==============================] - 0s 361us/step - loss: 4.2314 - xent_loss: 0.4969 - heat_loss: 3.7345\n",
      "Epoch 642/10000\n",
      "100/100 [==============================] - 0s 491us/step - loss: 4.2314 - xent_loss: 0.4969 - heat_loss: 3.7345\n",
      "Epoch 643/10000\n",
      "100/100 [==============================] - 0s 341us/step - loss: 4.2314 - xent_loss: 0.4969 - heat_loss: 3.7345\n",
      "Epoch 644/10000\n",
      "100/100 [==============================] - 0s 638us/step - loss: 4.2314 - xent_loss: 0.4969 - heat_loss: 3.7345\n",
      "Epoch 645/10000\n",
      "100/100 [==============================] - 0s 836us/step - loss: 4.2314 - xent_loss: 0.4969 - heat_loss: 3.7345\n",
      "Epoch 646/10000\n",
      "100/100 [==============================] - 0s 772us/step - loss: 4.2314 - xent_loss: 0.4969 - heat_loss: 3.7345\n",
      "Epoch 647/10000\n",
      "100/100 [==============================] - 0s 900us/step - loss: 4.2314 - xent_loss: 0.4969 - heat_loss: 3.7345\n",
      "Epoch 648/10000\n",
      "100/100 [==============================] - 0s 977us/step - loss: 4.2314 - xent_loss: 0.4969 - heat_loss: 3.7345\n",
      "Epoch 649/10000\n",
      "100/100 [==============================] - 0s 371us/step - loss: 4.2314 - xent_loss: 0.4969 - heat_loss: 3.7345\n",
      "Epoch 650/10000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.2314 - xent_loss: 0.4969 - heat_loss: 3.7345\n",
      "Epoch 651/10000\n",
      "100/100 [==============================] - 0s 431us/step - loss: 4.2314 - xent_loss: 0.4969 - heat_loss: 3.7345\n",
      "Epoch 652/10000\n",
      "100/100 [==============================] - 0s 391us/step - loss: 4.2314 - xent_loss: 0.4969 - heat_loss: 3.7345\n",
      "Epoch 653/10000\n",
      "100/100 [==============================] - 0s 401us/step - loss: 4.2313 - xent_loss: 0.4969 - heat_loss: 3.7345\n",
      "Epoch 654/10000\n",
      "100/100 [==============================] - 0s 401us/step - loss: 4.2313 - xent_loss: 0.4969 - heat_loss: 3.7345\n",
      "Epoch 655/10000\n",
      "100/100 [==============================] - 0s 341us/step - loss: 4.2313 - xent_loss: 0.4969 - heat_loss: 3.7345\n",
      "Epoch 656/10000\n",
      "100/100 [==============================] - 0s 321us/step - loss: 4.2313 - xent_loss: 0.4969 - heat_loss: 3.7345\n",
      "Epoch 657/10000\n",
      "100/100 [==============================] - 0s 322us/step - loss: 4.2313 - xent_loss: 0.4968 - heat_loss: 3.7345\n",
      "Epoch 658/10000\n",
      "100/100 [==============================] - 0s 446us/step - loss: 4.2313 - xent_loss: 0.4968 - heat_loss: 3.7345\n",
      "Epoch 659/10000\n",
      "100/100 [==============================] - 0s 511us/step - loss: 4.2313 - xent_loss: 0.4968 - heat_loss: 3.7345\n",
      "Epoch 660/10000\n",
      "100/100 [==============================] - 0s 441us/step - loss: 4.2313 - xent_loss: 0.4968 - heat_loss: 3.7345\n",
      "Epoch 661/10000\n",
      "100/100 [==============================] - 0s 381us/step - loss: 4.2313 - xent_loss: 0.4968 - heat_loss: 3.7345\n",
      "Epoch 662/10000\n",
      "100/100 [==============================] - 0s 341us/step - loss: 4.2313 - xent_loss: 0.4968 - heat_loss: 3.7345\n",
      "Epoch 663/10000\n",
      "100/100 [==============================] - 0s 321us/step - loss: 4.2313 - xent_loss: 0.4968 - heat_loss: 3.7345\n",
      "Epoch 664/10000\n",
      "100/100 [==============================] - 0s 391us/step - loss: 4.2313 - xent_loss: 0.4968 - heat_loss: 3.7345\n",
      "Epoch 665/10000\n",
      "100/100 [==============================] - 0s 431us/step - loss: 4.2313 - xent_loss: 0.4968 - heat_loss: 3.7345\n",
      "Epoch 666/10000\n",
      "100/100 [==============================] - 0s 351us/step - loss: 4.2313 - xent_loss: 0.4968 - heat_loss: 3.7345\n",
      "Epoch 667/10000\n",
      "100/100 [==============================] - 0s 359us/step - loss: 4.2313 - xent_loss: 0.4968 - heat_loss: 3.7345\n",
      "Epoch 668/10000\n",
      "100/100 [==============================] - 0s 361us/step - loss: 4.2313 - xent_loss: 0.4968 - heat_loss: 3.7345\n",
      "Epoch 669/10000\n",
      "100/100 [==============================] - 0s 321us/step - loss: 4.2313 - xent_loss: 0.4968 - heat_loss: 3.7345\n",
      "Epoch 670/10000\n",
      "100/100 [==============================] - 0s 391us/step - loss: 4.2313 - xent_loss: 0.4968 - heat_loss: 3.7345\n",
      "Epoch 671/10000\n",
      "100/100 [==============================] - 0s 351us/step - loss: 4.2312 - xent_loss: 0.4968 - heat_loss: 3.7345\n",
      "Epoch 672/10000\n",
      "100/100 [==============================] - 0s 381us/step - loss: 4.2312 - xent_loss: 0.4968 - heat_loss: 3.7345\n",
      "Epoch 673/10000\n",
      "100/100 [==============================] - 0s 622us/step - loss: 4.2312 - xent_loss: 0.4968 - heat_loss: 3.7345\n",
      "Epoch 674/10000\n",
      "100/100 [==============================] - 0s 391us/step - loss: 4.2312 - xent_loss: 0.4968 - heat_loss: 3.7345\n",
      "Epoch 675/10000\n",
      "100/100 [==============================] - 0s 331us/step - loss: 4.2312 - xent_loss: 0.4967 - heat_loss: 3.7345\n",
      "Epoch 676/10000\n",
      "100/100 [==============================] - 0s 331us/step - loss: 4.2312 - xent_loss: 0.4967 - heat_loss: 3.7345\n",
      "Epoch 677/10000\n",
      "100/100 [==============================] - 0s 351us/step - loss: 4.2312 - xent_loss: 0.4967 - heat_loss: 3.7345\n",
      "Epoch 678/10000\n",
      "100/100 [==============================] - 0s 491us/step - loss: 4.2312 - xent_loss: 0.4967 - heat_loss: 3.7345\n",
      "Epoch 679/10000\n",
      "100/100 [==============================] - 0s 491us/step - loss: 4.2312 - xent_loss: 0.4967 - heat_loss: 3.7345\n",
      "Epoch 680/10000\n",
      "100/100 [==============================] - 0s 481us/step - loss: 4.2312 - xent_loss: 0.4967 - heat_loss: 3.7345\n",
      "Epoch 681/10000\n",
      "100/100 [==============================] - 0s 468us/step - loss: 4.2312 - xent_loss: 0.4967 - heat_loss: 3.7345\n",
      "Epoch 682/10000\n",
      "100/100 [==============================] - 0s 509us/step - loss: 4.2312 - xent_loss: 0.4967 - heat_loss: 3.7345\n",
      "Epoch 683/10000\n",
      "100/100 [==============================] - 0s 831us/step - loss: 4.2312 - xent_loss: 0.4967 - heat_loss: 3.7345\n",
      "Epoch 684/10000\n",
      "100/100 [==============================] - 0s 900us/step - loss: 4.2312 - xent_loss: 0.4967 - heat_loss: 3.7345\n",
      "Epoch 685/10000\n",
      "100/100 [==============================] - 0s 900us/step - loss: 4.2312 - xent_loss: 0.4967 - heat_loss: 3.7345\n",
      "Epoch 686/10000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.2312 - xent_loss: 0.4967 - heat_loss: 3.7345\n",
      "Epoch 687/10000\n",
      "100/100 [==============================] - 0s 321us/step - loss: 4.2312 - xent_loss: 0.4967 - heat_loss: 3.7345\n",
      "Epoch 688/10000\n",
      "100/100 [==============================] - 0s 331us/step - loss: 4.2311 - xent_loss: 0.4967 - heat_loss: 3.7345\n",
      "Epoch 689/10000\n",
      "100/100 [==============================] - 0s 652us/step - loss: 4.2311 - xent_loss: 0.4967 - heat_loss: 3.7345\n",
      "Epoch 690/10000\n",
      "100/100 [==============================] - 0s 361us/step - loss: 4.2311 - xent_loss: 0.4967 - heat_loss: 3.7345\n",
      "Epoch 691/10000\n",
      "100/100 [==============================] - 0s 381us/step - loss: 4.2311 - xent_loss: 0.4967 - heat_loss: 3.7345\n",
      "Epoch 692/10000\n",
      "100/100 [==============================] - 0s 341us/step - loss: 4.2311 - xent_loss: 0.4966 - heat_loss: 3.7345\n",
      "Epoch 693/10000\n",
      "100/100 [==============================] - 0s 311us/step - loss: 4.2311 - xent_loss: 0.4966 - heat_loss: 3.7345\n",
      "Epoch 694/10000\n",
      "100/100 [==============================] - 0s 321us/step - loss: 4.2311 - xent_loss: 0.4966 - heat_loss: 3.7345\n",
      "Epoch 695/10000\n",
      "100/100 [==============================] - 0s 401us/step - loss: 4.2311 - xent_loss: 0.4966 - heat_loss: 3.7345\n",
      "Epoch 696/10000\n",
      "100/100 [==============================] - 0s 381us/step - loss: 4.2311 - xent_loss: 0.4966 - heat_loss: 3.7345\n",
      "Epoch 697/10000\n",
      "100/100 [==============================] - 0s 351us/step - loss: 4.2311 - xent_loss: 0.4966 - heat_loss: 3.7345\n",
      "Epoch 698/10000\n",
      "100/100 [==============================] - 0s 331us/step - loss: 4.2311 - xent_loss: 0.4966 - heat_loss: 3.7345\n",
      "Epoch 699/10000\n",
      "100/100 [==============================] - 0s 481us/step - loss: 4.2311 - xent_loss: 0.4966 - heat_loss: 3.7345\n",
      "Epoch 700/10000\n",
      "100/100 [==============================] - 0s 431us/step - loss: 4.2311 - xent_loss: 0.4966 - heat_loss: 3.7345\n",
      "Epoch 701/10000\n",
      "100/100 [==============================] - 0s 351us/step - loss: 4.2311 - xent_loss: 0.4966 - heat_loss: 3.7345\n",
      "Epoch 702/10000\n",
      "100/100 [==============================] - 0s 531us/step - loss: 4.2311 - xent_loss: 0.4966 - heat_loss: 3.7345\n",
      "Epoch 703/10000\n",
      "100/100 [==============================] - 0s 562us/step - loss: 4.2311 - xent_loss: 0.4966 - heat_loss: 3.7345\n",
      "Epoch 704/10000\n",
      "100/100 [==============================] - 0s 612us/step - loss: 4.2311 - xent_loss: 0.4966 - heat_loss: 3.7345\n",
      "Epoch 705/10000\n",
      "100/100 [==============================] - 0s 937us/step - loss: 4.2311 - xent_loss: 0.4966 - heat_loss: 3.7345\n",
      "Epoch 706/10000\n",
      "100/100 [==============================] - 0s 501us/step - loss: 4.2310 - xent_loss: 0.4966 - heat_loss: 3.7345\n",
      "Epoch 707/10000\n",
      "100/100 [==============================] - 0s 672us/step - loss: 4.2310 - xent_loss: 0.4966 - heat_loss: 3.7345\n",
      "Epoch 708/10000\n",
      "100/100 [==============================] - 0s 582us/step - loss: 4.2310 - xent_loss: 0.4966 - heat_loss: 3.7345\n",
      "Epoch 709/10000\n",
      "100/100 [==============================] - 0s 331us/step - loss: 4.2310 - xent_loss: 0.4966 - heat_loss: 3.7345\n",
      "Epoch 710/10000\n",
      "100/100 [==============================] - 0s 341us/step - loss: 4.2310 - xent_loss: 0.4965 - heat_loss: 3.7345\n",
      "Epoch 711/10000\n",
      "100/100 [==============================] - 0s 331us/step - loss: 4.2310 - xent_loss: 0.4965 - heat_loss: 3.7345\n",
      "Epoch 712/10000\n",
      "100/100 [==============================] - 0s 371us/step - loss: 4.2310 - xent_loss: 0.4965 - heat_loss: 3.7345\n",
      "Epoch 713/10000\n",
      "100/100 [==============================] - 0s 341us/step - loss: 4.2310 - xent_loss: 0.4965 - heat_loss: 3.7345\n",
      "Epoch 714/10000\n",
      "100/100 [==============================] - 0s 395us/step - loss: 4.2310 - xent_loss: 0.4965 - heat_loss: 3.7345\n",
      "Epoch 715/10000\n",
      "100/100 [==============================] - 0s 331us/step - loss: 4.2310 - xent_loss: 0.4965 - heat_loss: 3.7345\n",
      "Epoch 716/10000\n",
      "100/100 [==============================] - 0s 869us/step - loss: 4.2310 - xent_loss: 0.4965 - heat_loss: 3.7345\n",
      "Epoch 717/10000\n",
      "100/100 [==============================] - 0s 874us/step - loss: 4.2310 - xent_loss: 0.4965 - heat_loss: 3.7345\n",
      "Epoch 718/10000\n",
      "100/100 [==============================] - 0s 391us/step - loss: 4.2310 - xent_loss: 0.4965 - heat_loss: 3.7345\n",
      "Epoch 719/10000\n",
      "100/100 [==============================] - 0s 772us/step - loss: 4.2310 - xent_loss: 0.4965 - heat_loss: 3.7345\n",
      "Epoch 720/10000\n",
      "100/100 [==============================] - 0s 900us/step - loss: 4.2310 - xent_loss: 0.4965 - heat_loss: 3.7345\n",
      "Epoch 721/10000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.2310 - xent_loss: 0.4965 - heat_loss: 3.7345\n",
      "Epoch 722/10000\n",
      "100/100 [==============================] - 0s 471us/step - loss: 4.2309 - xent_loss: 0.4965 - heat_loss: 3.7345\n",
      "Epoch 723/10000\n",
      "100/100 [==============================] - 0s 451us/step - loss: 4.2309 - xent_loss: 0.4965 - heat_loss: 3.7345\n",
      "Epoch 724/10000\n",
      "100/100 [==============================] - 0s 331us/step - loss: 4.2309 - xent_loss: 0.4965 - heat_loss: 3.7345\n",
      "Epoch 725/10000\n",
      "100/100 [==============================] - 0s 351us/step - loss: 4.2309 - xent_loss: 0.4965 - heat_loss: 3.7345\n",
      "Epoch 726/10000\n",
      "100/100 [==============================] - 0s 361us/step - loss: 4.2309 - xent_loss: 0.4965 - heat_loss: 3.7345\n",
      "Epoch 727/10000\n",
      "100/100 [==============================] - 0s 351us/step - loss: 4.2309 - xent_loss: 0.4964 - heat_loss: 3.7345\n",
      "Epoch 728/10000\n",
      "100/100 [==============================] - 0s 662us/step - loss: 4.2309 - xent_loss: 0.4964 - heat_loss: 3.7345\n",
      "Epoch 729/10000\n",
      "100/100 [==============================] - 0s 259us/step - loss: 4.2309 - xent_loss: 0.4964 - heat_loss: 3.7345\n",
      "Epoch 730/10000\n",
      "100/100 [==============================] - 0s 371us/step - loss: 4.2309 - xent_loss: 0.4964 - heat_loss: 3.7345\n",
      "Epoch 731/10000\n",
      "100/100 [==============================] - 0s 371us/step - loss: 4.2309 - xent_loss: 0.4964 - heat_loss: 3.7345\n",
      "Epoch 732/10000\n",
      "100/100 [==============================] - 0s 311us/step - loss: 4.2309 - xent_loss: 0.4964 - heat_loss: 3.7345\n",
      "Epoch 733/10000\n",
      "100/100 [==============================] - 0s 334us/step - loss: 4.2309 - xent_loss: 0.4964 - heat_loss: 3.7345\n",
      "Epoch 734/10000\n",
      "100/100 [==============================] - 0s 368us/step - loss: 4.2309 - xent_loss: 0.4964 - heat_loss: 3.7345\n",
      "Epoch 735/10000\n",
      "100/100 [==============================] - 0s 332us/step - loss: 4.2309 - xent_loss: 0.4964 - heat_loss: 3.7345\n",
      "Epoch 736/10000\n",
      "100/100 [==============================] - 0s 932us/step - loss: 4.2309 - xent_loss: 0.4964 - heat_loss: 3.7345\n",
      "Epoch 737/10000\n",
      "100/100 [==============================] - 0s 396us/step - loss: 4.2309 - xent_loss: 0.4964 - heat_loss: 3.7345\n",
      "Epoch 738/10000\n",
      "100/100 [==============================] - 0s 572us/step - loss: 4.2309 - xent_loss: 0.4964 - heat_loss: 3.7345\n",
      "Epoch 739/10000\n",
      "100/100 [==============================] - 0s 700us/step - loss: 4.2309 - xent_loss: 0.4964 - heat_loss: 3.7345\n",
      "Epoch 740/10000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.2308 - xent_loss: 0.4964 - heat_loss: 3.7345\n",
      "Epoch 741/10000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.2308 - xent_loss: 0.4964 - heat_loss: 3.7345\n",
      "Epoch 742/10000\n",
      "100/100 [==============================] - 0s 381us/step - loss: 4.2308 - xent_loss: 0.4964 - heat_loss: 3.7345\n",
      "Epoch 743/10000\n",
      "100/100 [==============================] - 0s 381us/step - loss: 4.2308 - xent_loss: 0.4964 - heat_loss: 3.7345\n",
      "Epoch 744/10000\n",
      "100/100 [==============================] - 0s 441us/step - loss: 4.2308 - xent_loss: 0.4964 - heat_loss: 3.7345\n",
      "Epoch 745/10000\n",
      "100/100 [==============================] - 0s 411us/step - loss: 4.2308 - xent_loss: 0.4963 - heat_loss: 3.7345\n",
      "Epoch 746/10000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.2308 - xent_loss: 0.4963 - heat_loss: 3.7345\n",
      "Epoch 747/10000\n",
      "100/100 [==============================] - 0s 401us/step - loss: 4.2308 - xent_loss: 0.4963 - heat_loss: 3.7345\n",
      "Epoch 748/10000\n",
      "100/100 [==============================] - 0s 491us/step - loss: 4.2308 - xent_loss: 0.4963 - heat_loss: 3.7345\n",
      "Epoch 749/10000\n",
      "100/100 [==============================] - 0s 993us/step - loss: 4.2308 - xent_loss: 0.4963 - heat_loss: 3.7345\n",
      "Epoch 750/10000\n",
      "100/100 [==============================] - 0s 341us/step - loss: 4.2308 - xent_loss: 0.4963 - heat_loss: 3.7345\n",
      "Epoch 751/10000\n",
      "100/100 [==============================] - 0s 868us/step - loss: 4.2308 - xent_loss: 0.4963 - heat_loss: 3.7345\n",
      "Epoch 752/10000\n",
      "100/100 [==============================] - 0s 443us/step - loss: 4.2308 - xent_loss: 0.4963 - heat_loss: 3.7345\n",
      "Epoch 753/10000\n",
      "100/100 [==============================] - 0s 331us/step - loss: 4.2308 - xent_loss: 0.4963 - heat_loss: 3.7345\n",
      "Epoch 754/10000\n",
      "100/100 [==============================] - 0s 341us/step - loss: 4.2308 - xent_loss: 0.4963 - heat_loss: 3.7345\n",
      "Epoch 755/10000\n",
      "100/100 [==============================] - 0s 491us/step - loss: 4.2308 - xent_loss: 0.4963 - heat_loss: 3.7345\n",
      "Epoch 756/10000\n",
      "100/100 [==============================] - 0s 381us/step - loss: 4.2308 - xent_loss: 0.4963 - heat_loss: 3.7345\n",
      "Epoch 757/10000\n",
      "100/100 [==============================] - 0s 411us/step - loss: 4.2308 - xent_loss: 0.4963 - heat_loss: 3.7345\n",
      "Epoch 758/10000\n",
      "100/100 [==============================] - 0s 411us/step - loss: 4.2307 - xent_loss: 0.4963 - heat_loss: 3.7345\n",
      "Epoch 759/10000\n",
      "100/100 [==============================] - 0s 511us/step - loss: 4.2307 - xent_loss: 0.4963 - heat_loss: 3.7345\n",
      "Epoch 760/10000\n",
      "100/100 [==============================] - 0s 351us/step - loss: 4.2307 - xent_loss: 0.4963 - heat_loss: 3.7345\n",
      "Epoch 761/10000\n",
      "100/100 [==============================] - 0s 321us/step - loss: 4.2307 - xent_loss: 0.4963 - heat_loss: 3.7345\n",
      "Epoch 762/10000\n",
      "100/100 [==============================] - 0s 311us/step - loss: 4.2307 - xent_loss: 0.4962 - heat_loss: 3.7345\n",
      "Epoch 763/10000\n",
      "100/100 [==============================] - 0s 301us/step - loss: 4.2307 - xent_loss: 0.4962 - heat_loss: 3.7345\n",
      "Epoch 764/10000\n",
      "100/100 [==============================] - 0s 351us/step - loss: 4.2307 - xent_loss: 0.4962 - heat_loss: 3.7345\n",
      "Epoch 765/10000\n",
      "100/100 [==============================] - 0s 311us/step - loss: 4.2307 - xent_loss: 0.4962 - heat_loss: 3.7345\n",
      "Epoch 766/10000\n",
      "100/100 [==============================] - 0s 311us/step - loss: 4.2307 - xent_loss: 0.4962 - heat_loss: 3.7345\n",
      "Epoch 767/10000\n",
      "100/100 [==============================] - 0s 431us/step - loss: 4.2307 - xent_loss: 0.4962 - heat_loss: 3.7345\n",
      "Epoch 768/10000\n",
      "100/100 [==============================] - 0s 381us/step - loss: 4.2307 - xent_loss: 0.4962 - heat_loss: 3.7345\n",
      "Epoch 769/10000\n",
      "100/100 [==============================] - 0s 311us/step - loss: 4.2307 - xent_loss: 0.4962 - heat_loss: 3.7345\n"
     ]
    },
    {
     "ename": "SystemError",
     "evalue": "<built-in function EventsWriter_Flush> returned a result with an error set",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mSystemError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-33-20a6e0dee72b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     11\u001b[0m                   \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m                   \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtbCallback\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m                   validation_data=None, shuffle = False)\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;31m# Save the trained models\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1703\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1704\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1705\u001b[1;33m                               validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1706\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1707\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32mc:\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[1;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m   1253\u001b[0m                             \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_outs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1254\u001b[0m                                 \u001b[0mepoch_logs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'val_'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mo\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1255\u001b[1;33m             \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1256\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mcallback_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1257\u001b[0m                 \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\anaconda3\\lib\\site-packages\\keras\\callbacks.py\u001b[0m in \u001b[0;36mon_epoch_end\u001b[1;34m(self, epoch, logs)\u001b[0m\n\u001b[0;32m     75\u001b[0m         \u001b[0mlogs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlogs\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 77\u001b[1;33m             \u001b[0mcallback\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     78\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     79\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mon_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\anaconda3\\lib\\site-packages\\keras\\callbacks.py\u001b[0m in \u001b[0;36mon_epoch_end\u001b[1;34m(self, epoch, logs)\u001b[0m\n\u001b[0;32m    863\u001b[0m             \u001b[0msummary_value\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtag\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    864\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwriter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_summary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 865\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwriter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    866\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    867\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mon_train_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\anaconda3\\lib\\site-packages\\tensorflow\\python\\summary\\writer\\writer.py\u001b[0m in \u001b[0;36mflush\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    379\u001b[0m     \u001b[0mdisk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    380\u001b[0m     \"\"\"\n\u001b[1;32m--> 381\u001b[1;33m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevent_writer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    382\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    383\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\anaconda3\\lib\\site-packages\\tensorflow\\python\\summary\\writer\\event_file_writer.py\u001b[0m in \u001b[0;36mflush\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    117\u001b[0m     \"\"\"\n\u001b[0;32m    118\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_event_queue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 119\u001b[1;33m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_ev_writer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFlush\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    120\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    121\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\anaconda3\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\u001b[0m in \u001b[0;36mFlush\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    565\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    566\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mFlush\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 567\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_pywrap_tensorflow_internal\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mEventsWriter_Flush\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    568\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    569\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mClose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mSystemError\u001b[0m: <built-in function EventsWriter_Flush> returned a result with an error set"
     ]
    }
   ],
   "source": [
    "reduce_lr = ReduceLROnPlateau(monitor = 'xent_loss',\n",
    "                              factor = 0.5,\n",
    "                              patience = 20,\n",
    "                              mode = 'min',\n",
    "                              epsilon = 0.000001)\n",
    "\n",
    "tbCallback = TensorBoard(log_dir =log_dir_tensorboard)\n",
    "\n",
    "vae.fit(signals, signals,\n",
    "                  epochs=10000,\n",
    "                  batch_size=batch_size,\n",
    "                  callbacks=[tbCallback],\n",
    "                  validation_data=None, shuffle = False)\n",
    "\n",
    "# Save the trained models \n",
    "experiment_instance = timestr+extra_comments\n",
    "vae.save_weights(join(folder_models, experiment_instance+'.h5'))\n",
    "decoder.save(join(folder_dictionary['generator'], experiment_instance))\n",
    "encoder.save(join(folder_dictionary['encoder'], experiment_instance))\n",
    "encoder_sigma.save(join(folder_dictionary['encoder_sigma'], experiment_instance))\n",
    "vae.save(join(folder_dictionary['vae'], experiment_instance))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reconstruction testing\n",
    "predictions = vae.predict(signals, batch_size = batch_size)\n",
    "# Encoding generation\n",
    "x_train_encoded = encoder.predict(signals, batch_size=batch_size)\n",
    "# x_train_encoded_sigma = encoder_sigma.predict(signals, batch_size=batch_size)\n",
    "x_train_decoded = decoder.predict(x_train_encoded, batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Signal Reconstruction comparison\n",
    "fig, ax = plt.subplots(10,10)\n",
    "fig.set_figheight(20)\n",
    "fig.set_figwidth(20)\n",
    "for num_row, row in enumerate(ax):\n",
    "    for num_col, col in enumerate(row):\n",
    "        col.plot(time_range, predictions[np.ravel_multi_index((num_row,num_col),(10,10))],'-x')\n",
    "        col.plot(time_range, signals[np.ravel_multi_index((num_row,num_col),(10,10))],'-x')\n",
    "        col.set_xticks([])\n",
    "        col.set_yticks([])\n",
    "        col.set_xlabel(str(int(360*phase_range[np.ravel_multi_index((num_row,num_col),(10,10))]/(2*np.pi))))\n",
    "        col.grid()\n",
    "        \n",
    "\n",
    "plt.show()\n",
    "plt.savefig('Conv2DLatent2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10,10))\n",
    "plt.errorbar((360*phase_range/(2*np.pi)).astype(int),x_train_encoded[:,0],yerr=np.exp(log_t)*np.ones(len(x_train_encoded[:,0])),\n",
    "            fmt ='o')\n",
    "plt.xlabel('Phase in Degrees')\n",
    "plt.ylabel('Z1-dimension Mean')\n",
    "plt.title('Latent representation of signals with different phases')\n",
    "plt.grid()\n",
    "plt.savefig('Mean Z1D')\n",
    "# plt.figure(figsize = (10,10))\n",
    "# plt.scatter((360*phase_range/(2*np.pi)).astype(int),x_train_encoded_sigma[:,0])\n",
    "# plt.xlabel('Phase in Degrees')\n",
    "# plt.ylabel('Z1-dimension logStd')\n",
    "# plt.title('Latent representation of signals with different phases. Log of Standard Deviation.')\n",
    "# plt.grid()\n",
    "# plt.savefig('Log Std Z1D')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reload Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\anaconda3\\lib\\site-packages\\keras\\models.py:255: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "  warnings.warn('No training configuration found in save file: '\n"
     ]
    }
   ],
   "source": [
    "root_model_folder = \"C:\\\\Users\\\\Luis Pérez\\\\Documents\\\\Master\\\\TUE\\\\Final Project\\\\Python\\\\models\\\\HeatKernel2\"\n",
    "file_model = \"2018-04-03-18-11__\"\n",
    "vae = load_model(win32api.GetShortPathName(join(root_model_folder,'vae',file_model)), \n",
    "                           custom_objects={'latent_dim':latent_dim,\n",
    "                                           'batch_size': batch_size,\n",
    "                                           'xent_loss': xent_loss,\n",
    "                                           'vae_loss': vae_loss,\n",
    "                                           'heat_loss': heat_loss,\n",
    "                                           'epsilon_std':epsilon_std,\n",
    "                                          'tf':tf,\n",
    "                                          'L':L})\n",
    "encoder = load_model(win32api.GetShortPathName(join(root_model_folder,'encoder',file_model)), \n",
    "                           custom_objects={'latent_dim':latent_dim,\n",
    "                                           'batch_size': batch_size,\n",
    "                                           'xent_loss': xent_loss,\n",
    "                                           'vae_loss': vae_loss,\n",
    "                                           'heat_loss': heat_loss,\n",
    "                                           'epsilon_std':epsilon_std,\n",
    "                                          'tf':tf,\n",
    "                                          'L':L})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
